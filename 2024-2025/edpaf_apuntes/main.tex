\documentclass[a4paper, 12pt, extrafontsizes]{memoir}

\usepackage{preamble}

\begin{document}

\begin{titlingpage*}

    \vspace*{0.5cm}
  
    \begin{tikzpicture}[remember picture,overlay]
    
        \fill[black] ($(current page.north west)-(0cm,4cm)$) rectangle ($(current page.south east)-(0cm,-20.75cm)$);
    
    \end{tikzpicture}
    
    \centering
    
    \vspace{\baselineskip}

    {\fontsize{27.5pt}{0pt}\selectfont\textbf{\color{white}Ecuaciones en Derivadas Parciales}}

    \vspace{\baselineskip}

    {\fontsize{27.5pt}{0pt}\selectfont\textbf{\color{white}y Análisis de Fourier}}

    \vspace{5\baselineskip}
    
    {\color{black}\itshape\bfseries{
    
    Universidad de Málaga

    \vspace{0.5\baselineskip}
    
    Grado en Matemáticas
    
    \vspace{0.5\baselineskip}

    Curso 2024-2025
    
    }}
    
\end{titlingpage*}
  
\tableofcontents*
\thispagestyle{empty}  

\chapter{Introducción}

En este breve tema se introducen las ecuaciones que protagonizan esta asignatura. Antes de ello, se necesitan aclarar algunas cuestiones de notación.

Si $u$ es una función definida en un abierto de $\R^n$ e $i \in \{1,\mathellipsis,n\}$, la derivada parcial de $u$ respecto de la $i$-ésima variable se va a denotar por $u_{x_i}$. En particular, si $n = 2$, las derivadas parciales de $u$ también se denotarán por $u_x$ y $u_y$, y si $n = 3$, por $u_x$, $u_y$ y $u_z$. Si $j \in \{1,\mathellipsis,n\}$, a la derivada parcial de $u_{x_i}$ respecto de la $j$-ésima variable se le denotará $u_{x_ix_j}$; lo mismo para las derivadas parciales de órdenes superiores.

Si $u$ es una función que toma valores en $\R^n$ e $i,j \in \{1,\mathellipsis,n\}$, la componente $i$-ésima de $u$ será denotada por $u^i$, y su derivada parcial respecto a la $j$-ésima variable, por $u^i_{x_j}$.

Si $\Omega$ es un abierto de $\R^n$, $u \colon \Omega \to \R$ tiene derivadas parciales de orden $k \in \N$ y $x \in \Omega$, se denota
\[D^ku(x) = \{u_{x_{i_1}x_{i_2}\mathellipsis x_{i_k}}(x) \colon i_1,\mathellipsis,i_k \in \{1,\mathellipsis,n\}\}.\]
Obsérvese que $D^ku(x)$ es un conjunto con $n^k$ elementos. Por tanto, ordenando de alguna manera sus elementos, $D^ku(x)$ se identifica con un vector de $\R^{n^k}$, que es a lo que se llamará $D^ku(x)$ en la definición que sigue.

\begin{definition}
    Una \emph{ecuación en derivadas parciales de orden $m$ en $\R^n$} es una expresión de la forma
    \[F(x,u(x),D^1u(x),D^2u(x),\mathellipsis,D^mu(x)) = 0, \qquad x \in A, \tag{E}\]
    donde $F \colon A \to \R$ es una función dada y $A \subset \R^n \times \R \times \R^n \times \R^{n^2} \times \mathellipsis \times \R^{n^m}$. Si $\Omega$ es un abierto de $\R^n$, una función $u \colon \Omega \to \R$ se dice que es \emph{solución de \textup{(E)} en $\Omega$} cuando:
    \begin{itemize}
        \item $u \in \mathcal{C}^m(\Omega,\R)$.
        \item $(x,u(x),D^1u(x),D^2u(x),\mathellipsis,D^mu(x)) \in A$ para todo $x \in \Omega$.
        \item $F(x,u(x),D^1u(x),D^2u(x),\mathellipsis,D^mu(x) )=0$ para todo $x \in \Omega$.
    \end{itemize}
\end{definition}

Por ejemplo, una ecuación en derivadas parciales (en adelante EDP) de orden $1$ en $\R^n$ es una expresión de la forma
\[F(x,u(x),u_{x_1}(x),u_{x_2}(x),\mathellipsis,u_{x_n}(x)) = 0, \qquad x \in A,\]
donde $F \colon A \to \R$ y $A \subset \R^n \times \R \times \R^n$. Esta ecuación puede escribirse de forma más abreviada como
\[F(x,u,u_{x_1},u_{x_2},\mathellipsis,u_{x_n}) = 0, \qquad x \in A.\]

\begin{definition}
    Sea $\Omega$ un abierto de $\R^n$.
    \begin{itemize}
        \item Si $u \in \mathcal{C}^1(\Omega,\R^n)$, la \emph{divergencia de $u$} es la función $\divergencia{u} \colon \Omega \to \R$ dada por
        \[\divergencia{u}(x) = u^1_{x_1}(x)+u^2_{x_2}(x)+\mathellipsis+u^n_{x_n}(x).\]
        \item Si $u \in \mathcal{C}^1(\Omega,\R)$, el \emph{gradiente de $u$} es la función $\nabla{u} \colon \Omega \to \R^n$ dada por
        \[\nabla{u}(x) = (u_{x_1}(x),u_{x_2}(x),\mathellipsis,u_{x_n}(x)).\]
        \item Si $u \in \mathcal{C}^2(\Omega,\R)$, el \emph{laplaciano de $u$} es la función $\Delta{u} \colon \Omega \to \R$ dada por 
        \[\Delta{u}(x)=u_{x_1x_1}(x)+u_{x_2x_2}(x)+\mathellipsis+u_{x_nx_n}(x).\]
    \end{itemize}
\end{definition}

No existe una teoría general que abarque la resolución de todas las EDP conocidas, y es altamente improbable que exista en un futuro debido a la gran variedad de fenómenos físicos, geométricos y probabilísticos que se pueden modelar mediante estas ecuaciones. En consecuencia, el estudio de las EDP ha de centrarse en ecuaciones concretas. Las que se estudiarán en esta asignatura son las \emph{ecuaciones cuasilineales}, la \emph{ecuación de ondas}, la \emph{ecuación del calor} y la \emph{ecuación de Laplace}.

\chapter{Ecuaciones cuasilineales}

Si $\Omega$ es un abierto de $\R^n \times \R$ (que, evidentemente, se identifica con $\R^{n+1}$), a la proyección de $\Omega$ sobre $\R^n$ se le va a denotar por $\Omega'$.

\begin{definition}
    Sea $\Omega$ un abierto de $\R^{n} \times \R$ y sean $b_1,b_2,\mathellipsis,b_n,c \in \mathcal{C}^1(\Omega,\R)$ tales que $(b_1(x,y),b_2(x,y),\mathellipsis,b_n(x,y)) \neq (0,0,\mathellipsis,0)$
    para todo $(x,y) \in \Omega$. Una EDP de la forma
    \[b_1(x,u(x))u_{x_1}(x)+b_2(x,u(x))u_{x_2}(x)+\mathellipsis+b_n(x,u(x))u_{x_n}(x) = c(x,u(x)), \qquad x \in \Omega',\]
    o, más abreviadamente, de la forma
    \[b_1(x,u)u_{x_1}+b_2(x,u)u_{x_2}+\mathellipsis+b_n(x,u)u_{x_n} = c(x,u), \qquad x \in \Omega',\]
    se dice que es \emph{cuasilineal}. Si $c = 0$, la ecuación se dice que es \emph{cuasilineal homogénea}.
\end{definition}

De manera similar se definen las ecuaciones cuasilineales de órdenes superiores a $1$. En este tema se trabajará principalmente el caso $n = 2$, así que las ecuaciones a estudiar son aquellas de la forma
\[b_1(x,y,u)u_x+b_2(x,y,u)u_y = c(x,y,u), \qquad x \in \Omega', \tag{CL}\]
siendo $\Omega$ un abierto de $\R^2 \times \R$ y $b_1,b_2,c \in \mathcal{C}^1(\Omega,\R)$ tales que $(b_1(x,y,z),b_2(x,y,z)) \neq (0,0)$ para todo $(x,y,z) \in \Omega$.

\section{Curvas características}

\begin{definition}
    Sea $I \subset \R$ un intervalo abierto. Una \emph{curva característica de la ecuación \textup{(CL)}} no es más que una solución del sistema de ecuaciones diferenciales ordinarias
    \[
    \left\{\begin{alignedat}{2}
        \varphi_1'(t) &= b_1(\varphi_1(t),\varphi_2(t),\eta(t)), \qquad & t \in I, \\
        \varphi_2'(t) &= b_2(\varphi_1(t),\varphi_2(t),\eta(t)), \qquad & t \in I, \\
        \eta'(t) &= c(\varphi_1(t),\varphi_2(t),\eta(t)), \qquad & t \in I.
    \end{alignedat}\right.
    \]
    Este sistema se denomina \emph{sistema característico}, y la función $\varphi=(\varphi_1,\varphi_2)$ se dice que es una \emph{característica base}.
\end{definition}

Nótese que si $t \mapsto (\varphi_1(t),\varphi_2(t),\eta(t))$, $t \in I$, es solución del sistema característico, entonces $t \mapsto (\varphi_1(t+t_0),\varphi_2(t+t_0),\eta(t+t_0))$, $t \in I-t_0$, es también solución del sistema. Por tanto, no se pierde generalidad suponiendo que $0 \in I$.

\begin{example}
    Considérese la ecuación cuasilineal
    \[xu_x+yu_y=x^2, \qquad (x,y) \in \R^2.\]
    El sistema característico sería
    \[
    \left\{\begin{alignedat}{2}
        \varphi_1'(t) &= \varphi_1(t), \qquad & t \in I, \\
        \varphi_2'(t) &= \varphi_2(t), \qquad & t \in I, \\
        \eta'(t) &= \varphi_1(t)^2, \qquad & t \in I.
    \end{alignedat}\right.
    \]
    Resolviendo este sistema se obtiene que las curvas características de la ecuación son las funciones $(\varphi_1,\varphi_2,\eta) \colon I \to \R^3$ dadas por
    \[\varphi_1(t) = Ae^t, \qquad \varphi_2(t) = Be^t, \qquad \eta(t) = \frac{1}{2}A^2e^{2t}+C,\]
    con $A,B,C \in \R$ constantes.
\end{example}

\begin{proposition}
Sea $D \subset \R^3$ un dominio (abierto y conexo) y considérese la ecuación cuasilineal
\[b_1(x,y,u)u_x+b_2(x,y,u)u_y = c(x,y,u), \qquad (x,y) \in D'.\]
Sea $I \subset \R$ un intervalo abierto con $0 \in I$. Si $(x_0,y_0,z_0) \in D$, entonces existe una única curva característica $(\varphi_1,\varphi_2,\eta)$ definida en $I$ tal que
\[(\varphi_1(0),\varphi_2(0),\eta(0)) = (x_0,y_0,z_0).\]
\end{proposition}

\begin{proof}
    Fijado $(x_0,y_0,z_0) \in D$, por lo estudiado en tiempos pasados sobre ecuaciones diferenciales ordinarias, se conoce que el sistema característico junto con los datos iniciales $\varphi_1(0)=x_0$, $\varphi_2(0)=y_0$ y $\eta(0)=z_0$ tiene solución única en $I$.
\end{proof}

La proposición que sigue muestra que si la gráfica de una función está formada por curvas características de (CL), entonces esa función es solución de (CL). 

\begin{proposition}\label{pro:2.1.4}
    Sea $D \subset \R^3$ un dominio y considérese la ecuación cuasilineal
    \[b_1(x,y,u)u_x+b_2(x,y,u)u_y = c(x,y,u), \qquad (x,y) \in D'.\]
    Sea $\Omega$ un dominio de $\R^2$ y sea $u \in \mathcal{C}^1(\Omega,\R)$. Supóngase que:
    \begin{enumerate}
        \item $\Graf{u} \subset D$.
        \item Si $(x_0,y_0,u(x_0,y_0)) \in \Graf{u}$ y $\gamma \colon I \to \R^3$ es la única curva característica verificando $\gamma(0)=(x_0,y_0,u(x_0,y_0))$, entonces existe $\varepsilon > 0$ tal que $\gamma(t) \in \Graf{u}$ para todo $t \in (-\varepsilon,\varepsilon)$.
    \end{enumerate}
    Entonces $u$ es solución de \textup{(CL)}.
\end{proposition}

El recíproco es cierto, es decir, si una función resuelve (CL), entonces su gráfica está formada por curvas características.

\begin{proposition}
    Sea $D \subset \R^3$ un dominio y considérese la ecuación cuasilineal
    \[b_1(x,y,u)u_x+b_2(x,y,u)u_y = c(x,y,u), \qquad (x,y) \in D'.\]
    Sea $u \in \mathcal{C}^1(\Omega,\R)$ una solución de \textup{(CL)} en un dominio $\Omega \subset \R^2$. Sea $(x_0,y_0,u(x_0,y_0)) \in \Graf{u}$, sea $(\varphi,\eta) \colon I \to \R^3$ la única curva característica verificando $\varphi(0) = (x_0,y_0) $ y $\eta(0)=u(x_0,y_0)$, y sea $J \subset I$ un intervalo abierto con $0 \in J$ y $\varphi(J) \subset \Omega$. Entonces \[(\varphi(t),\eta(t)) \in \Graf{u}\] para todo $t \in J$.
\end{proposition}

\begin{corollary}
    Sea $D \subset \R^3$ un dominio y considérese la ecuación cuasilineal homogénea
    \[b_1(x,y,u)u_x+b_2(x,y,u)u_y =0, \qquad (x,y) \in D'.\]
    Sea $u \in \mathcal{C}^1(\Omega,\R)$ una solución de \textup{(CL)} en un dominio $\Omega \subset \R^2$. Sea $(x_0,y_0,u(x_0,y_0)) \in \Graf{u}$ y sea $(\varphi,\eta) \colon I \to \R^3$ la única curva característica verificando $\varphi(0) = (x_0,y_0) $ y $\eta(0)=u(x_0,y_0)$. Si $\varphi(I) \subset \Omega$, entonces
    \[u(\varphi(t)) = u(x_0,y_0)\]
    para todo $t \in I$.
\end{corollary}

\begin{proof}
    Por ser $c = 0$, se tiene que $\eta'(t) = 0$ para todo $t \in I$, luego $\eta$ es constante. Y como $\eta(0)=u(x_0,y_0)$, entonces $\eta(t) = u(x_0,y_0)$ para todo $t \in I$. Ahora bien, empleando la proposición anterior, $(\varphi(t),\eta(t)) = (\varphi(t),u(x_0,y_0)) \in \Graf{u}$ para todo $t \in I$, de donde se deduce inmediatamente lo que afirma el enunciado.
\end{proof}

\section{Método de las características}

\begin{definition}
    Sea $\Omega \subset \R^3$ un abierto y considérese la ecuación cuasilineal
    \[b_1(x,y,u)u_x+b_2(x,y,u)u_y = c(x,y,u), \qquad (x,y) \in \Omega'. \tag{CL}\]
    Sea $\Sigma \subset \Omega'$ una curva regular y sea $u_0 \in \mathcal{C}^1(\Sigma,\R)$. Se llama \emph{problema de Cauchy asociado a \textup{(CL)} con dato $u_0$ en $\Sigma$} al problema que consiste en hallar $u \in \mathcal{C}^1(\Omega')$ tal que
    \[
    \left\{\begin{alignedat}{3}
        b_1(x,y,u)u_x+b_2(x,y,u)u_y &= c(x,y,u), \qquad & (x,y) &\in \Omega', \\
        u(x,y) &= u_0(x,y), \qquad & (x,y) &\in \Sigma.
    \end{alignedat}\right.
    \]
\end{definition}

Que $\Sigma$ sea una curva regular quiere decir que existen $\delta > 0$ y $\sigma \colon (-\delta,\delta) \to \R^2$ (denotamos $I_\delta = (-\delta,\delta)$ por comodidad) de manera que $\sigma \in \mathcal{C}^1(I_\delta,\R^2)$, $\sigma'(s) \neq (0,0)$ para todo $s \in I_\delta$ y $\sigma(I_\delta) = \Sigma$. Así, llamando $\tau = u_0 \circ \sigma$, el problema de Cauchy
\[
    \left\{\begin{alignedat}{3}
        b_1(x,y,u)u_x+b_2(x,y,u)u_y &= c(x,y,u), \qquad & (x,y) &\in \Omega', \\
        u(x,y) &= u_0(x,y), \qquad & (x,y) &\in \Sigma,
    \end{alignedat}\right.
\]
también puede escribirse como
\[
    \left\{\begin{alignedat}{3}
        b_1(x,y,u)u_x+b_2(x,y,u)u_y &= c(x,y,u), \qquad & (x,y) &\in \Omega', \\
        u(\sigma(s)) &= u_0 (\sigma(s)), \qquad & s &\in I_\delta.
    \end{alignedat}\right.
\]

\begin{theorem}
    Considérese el problema de Cauchy
    \[
    \left\{\begin{alignedat}{2}
        b_1(x,y,u)u_x+b_2(x,y,u)u_y &= c(x,y,u), \qquad & (x,y) \in \Omega', \\
        u(\sigma(s)) &= \tau(s), \qquad & s \in I_\delta.
    \end{alignedat}\right.
    \]
    Supóngase que $(\sigma(s),\tau(s)) \in \Omega$ para todo $s \in I_\delta$, y sea $\overline{s} \in I_\delta$ tal que
    \[\textup{det}\left(
        \begin{array}{cc}
            \sigma_1'(\overline{s}) & b_1(\sigma(\overline{s}),\tau(\overline{s})) \\
            \sigma_2'(\overline{s}) & b_2(\sigma(\overline{s}),\tau(\overline{s}))
        \end{array}
    \right) \neq 0.\]
    Entonces el problema de Cauchy tiene solución en un entorno de $\sigma(\overline{s})$.  
\end{theorem}

El método de resolución de problemas de Cauchy asociados a ecuaciones cuasilineales que se expondrá en los ejemplos siguientes se conoce como \emph{método de las características}.

\begin{example}
    Se trata de resolver el problema de Cauchy
    \[
    \left\{\begin{alignedat}{3}
        uu_x+u_y &= 1, \qquad & (x,y) &\in \R^2, \\
        u(x,x) &= 0, \qquad & x &\in \R.
    \end{alignedat}\right.
    \]
    Sean $\sigma \colon \R \to \R^2$ y $\tau \colon \R \to \R$ las funciones dadas por $\sigma(s) = (s,s)$ y $\tau(s)=u_0(\sigma(s)) = 0$. Para todo $\overline{s} \in \R$ se tiene
    \[\textup{det}\left(
        \begin{array}{cc}
            \sigma_1'(\overline{s}) & b_1(\sigma(\overline{s}),\tau(\overline{s})) \\
            \sigma_2'(\overline{s}) & b_2(\sigma(\overline{s}),\tau(\overline{s}))
        \end{array}
    \right) = \textup{det}\left(
        \begin{array}{cc}
            1 & 0 \\
            1 & 1
        \end{array}
    \right) = 1 \neq 0.\]
    Por tanto, el sistema tiene solución en un entorno de $(\overline{s},\overline{s})$ para todo $\overline{s} \in \R$. Hallémosla utilizando la \hyperref[pro:2.1.4]{\color{gray}Proposición 2.1.4}. Fijado $\overline{s} \in \R$, el objetivo es hallar la curva característica que en $0$ pasa por $(\sigma(\overline{s}),\tau(\overline{s})) = (\overline{s},\overline{s},0)$. El sistema característico es
    \[
    \left\{\begin{alignedat}{2}
        \varphi_1'(t) &= \eta(t), \qquad & t \in I, \\
        \varphi_2'(t) &= 1, \qquad & t \in I, \\
        \eta'(t) &= 1, \qquad & t \in I,
    \end{alignedat}\right.
    \]
    siendo $I$ un intervalo abierto con $0 \in I$. Las soluciones de este sistema son las funciones $(\varphi_1,\varphi_2,\eta) \colon I \to \R$ dadas por
    \[\varphi_1(t) = \frac{t^2}{2}+Ct+A, \qquad \varphi_2(t) = t+B, \qquad \eta(t) = t+C,\]
    donde $A,B,C \in \R$ son constantes. Se tiene que
    \begin{itemize}
        \item $\varphi_1(0)=\overline{s} \iff A = \overline{s}$.
        \item $\varphi_2(0)=\overline{s} \iff B = \overline{s}$.
        \item $\eta(0)=0 \iff C = 0$.
    \end{itemize}
    Para cada $(s,t) \in \R \times I$, sean
    \[\varphi_1(s,t) = \frac{t^2}{2}+s, \qquad \varphi_2(s,t) = t+s, \qquad \eta(s,t) = t,\]
    y considérese el conjunto
    \[S =  \left\{(\varphi(s,t),\eta(s,t)) \colon s \in \R, t \in I\right\} = \left\{\left(\frac{t^2}{2}+s,t+s,t\right) \colon s \in \R, t \in I\right\}\]
    Si se escribe $S$ como la gráfica de alguna función de clase $1$, la \hyperref[pro:2.1.4]{\color{gray}Proposición 2.1.4} brindará la solución buscada. Se tiene que
    \[
        \left\{\begin{alignedat}{2}
            \frac{t^2}{2}+s &= x \\
            t+s &= y
        \end{alignedat}\right. \iff \left\{\begin{alignedat}{2}
            t &= 1 \pm \sqrt{1-2(y-x)} \\
            s &= y -1 \mp \sqrt{1-2(y-x)}
        \end{alignedat}\right.
    \]
    Teniendo en cuenta que $t \in I$ y que $I$ es un intervalo abierto con $0 \in I$, en realidad se tiene
    \[
        \left\{\begin{alignedat}{2}
            \frac{t^2}{2}+s &= x \\
            t+s &= y
        \end{alignedat}\right. \iff \left\{\begin{alignedat}{2}
            t &= 1 - \sqrt{1-2(y-x)} \\
            s &= y -1 + \sqrt{1-2(y-x)}
        \end{alignedat}\right.
    \]
    Todo esto es válido siempre que $1-2(y-x) \geq 0$, es decir, siempre que $ y \leq \frac{1}{2}+x$. Sea
    \[U = \{(x,y) \in \R^2 \colon y < \frac{1}{2}+x\}.\]
    Entonces
    \[S =  \left\{\left(\frac{t^2}{2}+s,t+s,t\right) \colon s \in \R, t \in I\right\} = \{(x,y,1-\sqrt{1-2(y-x)}) \colon (x,y) \in U \},\]
    es decir,
    \[S =  \left\{(\varphi(s,t),\eta(s,t)) \colon s \in \R, t \in I\right\} = \{(x,y,u(x,y)) \colon (x,y) \in U \},\]
    siendo $u \colon U \to \R$ la función dada por $u(x,y) = 1-\sqrt{1-2(y-x)}$. Por la \hyperref[pro:2.1.4]{\color{gray}Proposición 2.1.4}, $u$ es solución del problema de partida. Nótese además que $u$ es una solución del problema en un entorno de $(\overline{s},\overline{s})$ para todo $\overline{s} \in \R$, como adelantaba el teorema de existencia.
\end{example}

\begin{example}
    Sea $\alpha \in \R$ con $\alpha \neq 0$. Se trata de resolver el problema de Cauchy
    \[
    \left\{\begin{alignedat}{3}
        u_x+\alpha u_y &= 0, \qquad & (x,y) &\in \R^2, \\
        u(x,0) &= e^x, \qquad & x &\in \R.
    \end{alignedat}\right.
    \]
    Sean $\sigma \colon \R \to \R^2$ y $\tau \colon \R \to \R$ las funciones dadas por $\sigma(s) = (s,0)$ y $\tau(s)=u_0(\sigma(s)) = e^s$. Para todo $\overline{s} \in \R$ se tiene
    \[\textup{det}\left(
        \begin{array}{cc}
            \sigma_1'(\overline{s}) & b_1(\sigma(\overline{s}),\tau(\overline{s})) \\
            \sigma_2'(\overline{s}) & b_2(\sigma(\overline{s}),\tau(\overline{s}))
        \end{array}
    \right) = \textup{det}\left(
        \begin{array}{cc}
            1 & 1 \\
            0 & \alpha
        \end{array}
    \right) = \alpha \neq 0.\]
    Por tanto, el sistema tiene solución en un entorno de $(\overline{s},\overline{s})$ para todo $\overline{s} \in \R$. Hallémosla utilizando la \hyperref[pro:2.1.4]{\color{gray}Proposición 2.1.4}. Fijado $\overline{s} \in \R$, el objetivo es hallar la curva característica que en $0$ pasa por $(\sigma(\overline{s}),\tau(\overline{s})) = (\overline{s},0,e^{\overline{s}})$. El sistema característico es
    \[
    \left\{\begin{alignedat}{2}
        \varphi_1'(t) &= 1, \qquad & t \in I, \\
        \varphi_2'(t) &= \alpha, \qquad & t \in I, \\
        \eta'(t) &= 0, \qquad & t \in I,
    \end{alignedat}\right.
    \]
    siendo $I$ un intervalo abierto con $0 \in I$. Las soluciones de este sistema son las funciones $(\varphi_1,\varphi_2,\eta) \colon I \to \R$ definidas por
    \[\varphi_1(t) = t+A, \qquad \varphi_2(t) = \alpha t+B, \qquad \eta(t) = C,\]
    donde $A,B,C \in \R$ son constantes. Se tiene que
    \begin{itemize}
        \item $\varphi_1(0)=\overline{s} \iff A = \overline{s}$.
        \item $\varphi_2(0)=0 \iff B = 0$.
        \item $\eta(0)=e^{\overline{s}} \iff C = e^{\overline{s}}$.
    \end{itemize}
    Para cada $(s,t) \in \R \times I$, sean
    \[\varphi_1(s,t) = t+s, \qquad \varphi_2(s,t) = \alpha t, \qquad \eta(s,t) = e^s,\]
    y considérese el conjunto
    \[S =  \left\{(\varphi(s,t),\eta(s,t)) \colon s \in \R, t \in I\right\} = \{(t+s,\alpha t, e^s) \colon s \in \R, t \in I\}\]
    Si se escribe $S$ como la gráfica de alguna función de clase $1$, la \hyperref[pro:2.1.4]{\color{gray}Proposición 2.1.4} nos dará la solución buscada. Se tiene que
    \[
        \left\{\begin{alignedat}{2}
            t+s &= x \\
            \alpha t &= y
        \end{alignedat}\right. \iff \left\{\begin{alignedat}{2}
            t &= \frac{y}{\alpha} \\
            s &= x-\frac{y}{\alpha}
        \end{alignedat}\right.
    \]
    Todo esto es válido para todo $x,y \in \R$. Por tanto,
    \[S =  \{(t+s,\alpha t, e^s) \colon s \in \R, t \in I\} = \{(x,y,e^{x-\frac{y}{\alpha}}) \colon (x,y) \in \R^2 \},\]
    es decir,
    \[S =  \left\{(\varphi(s,t),\eta(s,t)) \colon s \in \R, t \in I\right\} = \{(x,y,u(x,y)) \colon (x,y) \in \R^2 \},\]
    siendo $u \colon \R^2 \to \R$ la función dada por $u(x,y) = e^{x-\frac{y}{\alpha}}$. Por la \hyperref[pro:2.1.4]{\color{gray}Proposición 2.1.4}, $u$ es solución del problema de partida.
\end{example}

\chapter{Ecuación de ondas}

\begin{definition}
    Sea $I \subset \R^n$ un intervalo abierto, sea $T \in \R$ con $0 < T \leq \infty$, sea $c \in \R$ y sea $F \in \mathcal{C}(I \times (0,T))$. La \emph{ecuación de ondas} es
    \[u_{tt}(x,t) - c^2\Delta_xu(x,t) = F(x,t), \qquad x \in I, \ t \in (0,T),\]
    donde $\Delta_xu(x,t) = u_{x_1x_1}(x,t)+u_{x_2x_2}(x,t)+\mathellipsis+u_{x_nx_n}(x,t)$. Si $F = 0$, se habla de \emph{ecuación de ondas homogénea}.
\end{definition}

Concretamente, en este tema se trabajará con la ecuación de ondas en dimensión $1$, que no es más que
\[u_{tt}(x,t) - c^2u_{xx}(x,t) = F(x,t), \qquad x \in (a,b), \ t \in (0,T),\]
siendo $-\infty \leq a < b \leq \infty$.

Esta ecuación sirve para modelar las vibraciones de una cuerda tensa, que se identifica con el intervalo $(a,b)$. Si $u$ resuelve la ecuación anterior, el número real $u(x,t)$ es la altura de la cuerda a la que se encuentra en el punto $x$ en el instante $t$.

\section{Problema inicial asociado a la ecuación de ondas homogénea}

\begin{theorem}[Solución general de la ecuación de ondas homogénea]\label{teo:3.0.2}
    Una función $u \in \mathcal{C}^2(\R \times (0,\infty))$ es solución de la ecuación
    \[u_{tt}(x,t) - c^2u_{xx}(x,t) = 0, \qquad x \in \R, \ t >0, \tag{$\textup{O}_h$}\]
    si y solo si existen $f,g \in \mathcal{C}^2(\R)$ tales que
    \[u(x,t)=f(x+ct)+g(x-ct), \qquad x \in \R, \ t > 0.\]
\end{theorem}

\begin{proof}
    La idea de la demostración es, en términos informales, \emph{hacer el cambio de variable $\xi = x+ct$, $\eta = x-ct$}. Considérese la ecuación
    \[v_{\xi \eta}(\xi, \eta) = 0, \qquad \xi,\eta \in \R, \ \eta < \xi. \tag{$\widetilde{\textup{O}}_h$}\]
    Haciendo un par de cuentas sencillas se demuestra que
    \[u \textup{ es solución de ($\textup{O}_h$)} \iff (x,t) \mapsto u\left(\frac{\xi-\eta}{2},\frac{\xi+\eta}{2c}\right) \textup{ es solución de ($\widetilde{\textup{O}}_h$).} \tag{$\ast$}\]
    Se trata entonces de resolver la ecuación ($\widetilde{\textup{O}}_h$). Supóngase que $v$ es una solución de ($\widetilde{\textup{O}}_h$). Fijado $\overline{\xi} \in \R$, debe tenerse
    \[v_{\xi\eta}(\overline{\xi},\eta) = 0, \qquad \eta \in \R, \ \eta < \overline{\xi},\]
    luego existe una constante $h(\overline{\xi})\in \R$ tal que
    \[v_\xi(\overline{\xi},\eta) = h(\overline{\xi}), \qquad \eta \in \R, \ \eta < \overline{\xi},\]
    Por tanto, fijando ahora $\overline{\eta} \in \R$, debe cumplirse
    \[v_\xi(\xi,\overline{\eta}) = h(\xi), \qquad \xi \in \R, \ \overline{\eta} < \xi,\]
    luego 
    \[v(\xi, \overline{\eta}) = f(\xi) + g(\overline{\eta}), \qquad \xi \in \R, \ \overline{\eta} < \xi,\]
    donde $f$ es una primitiva de $h$ (nótese que $h \in \mathcal{C}^1(\R)$ porque $v_\xi(\xi,\eta) = h(\xi)$ para todo $\xi \in \R$ y $v$ es de clase $2$). En resumen,
    \[v(\xi, \eta) = f(\xi) + g(\eta), \qquad \xi,\eta \in \R, \ \eta < \xi,\]
    siendo $f,g \in \mathcal{C}^2(\R)$ ($f \in \mathcal{C}^2(\R)$ porque $h \in \mathcal{C}^1(\R)$, y que $g \in \mathcal{C}^2(\R)$ se obtiene despejando de la igualdad anterior). Claramente, la función $v$ así definida es solución de ($\widetilde{\textup{O}}_h$), así que se ha probado que
    \[v \textup{ es solución de ($\widetilde{\textup{O}}_h$)} \iff \exists \ f,g \in \mathcal{C}^2(\R) \textup{ con } v(\xi,\eta) = f(\xi)+g(\eta), \qquad \xi,\eta \in \R, \ \eta < \xi.\]
    Uniendo esto con $(\ast)$, se obtiene que
    \begin{align*}
        u \textup{ es sol. de ($\textup{O}_h$)} &\iff(x,t) \mapsto u\left(\frac{\xi-\eta}{2},\frac{\xi+\eta}{2c}\right) \textup{ es solución de ($\widetilde{\textup{O}}_h$).} \\ &\iff \exists \ f,g \in \mathcal{C}^2(\R) \textup{ con } u\left(\frac{\xi-\eta}{2},\frac{\xi+\eta}{2c}\right) = f(\xi)+g(\eta), \qquad \xi,\eta \in \R, \ \eta < \xi. \\
        &\iff \exists \ f,g \in \mathcal{C}^2(\R) \textup{ con } u(x,t) = f(x+ct)+g(x-ct), \qquad x \in \R, \ t > 0. \qedhere
    \end{align*}
\end{proof}

\begin{definition}
    Considérese la ecuación de ondas homogénea,
    \[u_{tt}(x,t) - c^2u_{xx}(x,t) = 0, \qquad x \in (a,b), \ t \in (0,T), \tag{$\textup{O}_h$}\]
    sean $u_0,u_1 \in \mathcal{C}(\R)$ y sean $I = (a,b)$, $J = (0,T)$. Se llama \emph{problema inicial asociado a \textup{($\textup{O}_h$)} con datos iniciales $u_0$ y $u_1$} al problema que consiste en hallar $u \in \mathcal{C}^2(I \times J) \cap \mathcal{C}^{0,1}(\overline{I} \times \overline{J})$ tal que
    \[
    \left\{\begin{alignedat}{3}
        u_{tt}(x,t)-c^2u_{xx}(x,t) &= 0, \qquad & x &\in I, \ t \in J, \\
        u(x,0) &= u_0(x), \qquad & x &\in \overline{I}, \\
        u_t(x,0) &= u_1(x), \qquad & x &\in \overline{I}.
    \end{alignedat}\right.
    \]
\end{definition}

Por si cupiese duda, que $u \in \mathcal{C}^{0,1}(\overline{I} \times \overline{J})$ quiere decir que $u$ es continua respecto de $x$ y de clase $1$ respecto de $t$, entendiéndose que en $t=0$ se habla de derivada lateral, es decir, \[u_t(x,0) = \lim_{t \to 0^+} \frac{u(x,t)-u(x,0)}{t}.\]

Esto de llamar $I = (a,b)$ y $J = (0,T)$ se hace porque las igualdades $\overline{I} = [a,b]$ y $\overline{J} = [0,T]$ pueden causar inconvenientes en caso de que $a$, $b$ o $T$ sean infinitos.

\begin{theorem}[Fórmula de D'Alembert]
    Si $u_0 \in \mathcal{C}^2(\R)$ y $u_1 \in \mathcal{C}^1(\R)$, entonces la única solución del problema
        \[
        \left\{\begin{alignedat}{3}
            u_{tt}(x,t)-c^2u_{xx}(x,t) &= 0, \qquad & x &\in \R, \ t > 0, \\
            u(x,0) &= u_0(x), \qquad & x &\in \R, \\
            u_t(x,0) &= u_1(x), \qquad & x &\in \R,
        \end{alignedat}\right.
        \]
    es la función $u \colon \R \times [0,\infty) \to \R$ dada por
    \[u(x,t) = \frac{1}{2}(u_0(x+ct)+u_0(x-ct))+\frac{1}{2c}\int_{x-ct}^{x+ct}u_1(s) \, ds.\]
\end{theorem}

\begin{proof}
    El \hyperref[teo:3.0.2]{\color{gray}teorema 3.0.2} dice que la solución del problema del enunciado, en caso de que exista, viene dada por
    \[u(x,t) = f(x+ct)+g(x-ct), \qquad x \in \R, \ t > 0,\]
    con $f,g \in \mathcal{C}^2(\R)$. Para todo $x \in \R$,
    \[u(x,0) = u_0(x) \iff f(x)+g(x) = u_0(x). \tag{$\ast$}\]
    Por otra parte, $u_t(x,t) = cf'(x+ct)-cg'(x-ct)$, luego
    \[u_t(x,0) = u_1(x) \iff cf'(x)-cg'(x) = u_1(x). \tag{$\ast\ast$}\]
    Derivando en $(\ast)$,
    \[f'(x)+g'(x)=u_0'(x),\]
    es decir,
    \[-cf'(x)-cg'(x)=-cu_0'(x),\]
    y restándole esto a $(\ast\ast)$ se obtiene
    \[2cf'(x) =u_1(x)+cu_0'(x),\]
    o sea,
    \[f'(x) = \frac{1}{2c}u_1(x)+\frac{1}{2}u_0'(x),\]
    luego existe $K \in \R$ tal que
    \[f(x) = \frac{1}{2c}\int_0^x u_1(s)\, ds + \frac{1}{2}u_0(x) + K.\]
    Llevando esto a $(\ast)$,
    \[g(x)=u_0(x)-f(x) =  \frac{1}{2}u_0(x) -\frac{1}{2c}\int_0^x u_1(s)\, ds - K.\]
    Por tanto,
    \begin{align*}
        u(x,t) &= f(x+ct)+g(x-ct) \\
        &= \frac{1}{2c}\int_0^{x+ct} u_1(s)\, ds + \frac{1}{2}u_0(x+ct) + K +\frac{1}{2}u_0(x-ct) -\frac{1}{2c}\int_0^{x-ct} u_1(s)\, ds - K. \\
        &= \frac{1}{2}(u_0(x+ct)+u_0(x-ct)) + \frac{1}{2c}\int_{x-ct}^{x+ct} u_1(s)\, ds.
    \end{align*}
    En resumen, la función $u \colon \R \times [0,\infty) \to \R$ así definida es solución de la ecuación (O) (gracias al \hyperref[teo:3.0.2]{\color{gray}teorema 3.0.2}), y por cómo se han escogido $f$ y $g$, se tiene que $u$ verifica las condiciones iniciales. La unicidad también es consecuencia directa del \hyperref[teo:3.0.2]{\color{gray}teorema 3.0.2}.
\end{proof}

\section{Problema inicial asociado a la ecuación de ondas no homogénea}

\begin{definition}
    Considérese la ecuación de ondas en $\R \times (0,\infty)$,
    \[u_{tt}(x,t) - c^2u_{xx}(x,t) = F(x,t), \qquad x \in \R, \ t >0, \tag{$\textup{O}$}\]
    y sean $u_0,u_1 \in \mathcal{C}(\R)$. Se llama \emph{problema inicial asociado a \textup{($\textup{O}$)} con datos iniciales $u_0$ y $u_1$} al problema que consiste en hallar $u \in \mathcal{C}^2(\R \times (0,\infty)) \cap \mathcal{C}^{0,1}(\R \times [0,\infty))$ tal que
    \[
    \left\{\begin{alignedat}{3}
        u_{tt}(x,t)-c^2u_{xx}(x,t) &= F(x,t), \qquad & x &\in \R, \ t > 0, \\
        u(x,0) &= u_0(x), \qquad & x &\in \R, \\
        u_t(x,0) &= u_1(x), \qquad & x &\in \R.
    \end{alignedat}\right.
    \]
\end{definition}

\begin{proposition}
    El problema de inicial asociado a la ecuación de ondas no homogénea tiene, a lo sumo, una solución.
\end{proposition}

\begin{proof}
    Si $u$ y $v$ son soluciones del problema, entonces $u-v$ es solución del problema asociado a $(\textup{O}_h)$ con datos iniciales nulos. Pero este problema tiene solución única y la función nula también lo resuelve... Debe ser entonces $u-v= 0$, o sea, $u= v$.
\end{proof}

Obsérvese que si $v$ es solución del problema asociado a (O) con datos iniciales nulos y $w$ es solución del problema asociado a $(\textup{O}_h)$ con datos iniciales $u_0$ y $u_1$, entonces $u=v+w$ es solución del problema asociado a (O) con datos iniciales $u_0$ y $u_1$. Además, por la proposición anterior, $u$ es la única solución de dicho problema.

Por tanto, es suficiente resolver el problema asociado a (O) con datos iniciales $u_0 = 0$ y $u_1 = 0$ para obtener la única solución del problema general.

\begin{theorem}[Principio de Duhamel]
    Sea $F \in \mathcal{C}^1(\R^2)$ y sea $u \colon \R \times [0,\infty) \to \R$ la función dada por
    \[u(x,t)=\frac{1}{2c}\int_0^t\left( \int_{x-c(t-\tau)}^{x+c(t-\tau)}F(\sigma,\tau) \, d\sigma\right) d\tau\]
    Entonces $u$ es solución del problema
    \[
    \left\{\begin{alignedat}{3}
        u_{tt}(x,t)-c^2u_{xx}(x,t) &= F(x,t), \qquad & x &\in \R, \ t > 0, \\
        u(x,0) &= 0, \qquad & x &\in \R, \\
        u_t(x,0) &= 0, \qquad & x &\in \R.
    \end{alignedat}\right.
    \]
\end{theorem}

\section{Problemas mixtos asociados a la ecuación de ondas}

\begin{definition}\label{def:3.3.1}
    Sean $L,T \in (0,\infty)$ y considérese la ecuación de ondas homogénea en $(0,L) \times (0,T)$,
    \[u_{tt}(x,t) - c^2u_{xx}(x,t) = 0, \qquad x \in (0,L), \ t\in(0,T). \tag{$\textup{O}_h$}\]
    Sean $u_0,u_1 \in \mathcal{C}([0,L])$.
    \begin{enumerate}
        \item Se llama \emph{problema mixto de Dirichlet asociado a \textup{($\textup{O}_h$)} con datos iniciales $u_0$ y $u_1$} al problema que consiste en hallar $u \in \mathcal{C}^2((0,L) \times (0,T)) \cap \mathcal{C}^{0,1}([0,L] \times [0,T])$ tal que
        \[
        \textup{(PMD)} \ \left\{\begin{alignedat}{5}
            u_{tt}(x,t)-c^2u_{xx}(x,t) &= 0, \qquad & x &\in (0,L), \ & t &\in (0,T), \\
            u(x,0) &= u_0(x), \qquad & x &\in [0,L], & & \\
            u_t(x,0) &= u_1(x), \qquad & x &\in [0,L], & & \\
            u(0,t) &= 0, \qquad & & & t &\in [0,T], \\
            u(L,t) &= 0, \qquad & & & t &\in [0,T].
        \end{alignedat}\right.
        \]
        En este contexto, las condiciones
        \[\left\{\begin{alignedat}{1}
            u(0,t) &= 0, \qquad t \in [0,T], \\
            u(L,t) &= 0, \qquad t \in [0,T],
        \end{alignedat}\right.\]
        se denominan \emph{condiciones de Dirichlet homogéneas}.
        \item Se llama \emph{problema mixto de Neumann asociado a \textup{($\textup{O}_h$)} con datos iniciales $u_0$ y $u_1$} al problema que consiste en hallar $u \in \mathcal{C}^2((0,L) \times (0,T)) \cap \mathcal{C}^{0,1}([0,L] \times [0,T])$ tal que
        \[
        \textup{(PMN)} \ \left\{\begin{alignedat}{5}
            u_{tt}(x,t)-c^2u_{xx}(x,t) &= 0, \qquad & x &\in (0,L), \ & t &\in (0,T), \\
            u(x,0) &= u_0(x), \qquad & x &\in [0,L], & & \\
            u_t(x,0) &= u_1(x), \qquad & x &\in [0,L], & & \\
            u_x(0,t) &= 0, \qquad & & & t &\in [0,T], \\
            u_x(L,t) &= 0, \qquad & & & t &\in [0,T].
        \end{alignedat}\right.
        \]
        En este contexto, las condiciones
        \[\left\{\begin{alignedat}{1}
            u_x(0,t) &= 0, \qquad t \in [0,T], \\
            u_x(L,t) &= 0, \qquad t \in [0,T],
        \end{alignedat}\right.\]
        se denominan \emph{condiciones de Neumann homogéneas}.
    \end{enumerate}
\end{definition}

Como siempre, al hablar de derivadas parciales respecto de $x$ en los puntos $(0,t)$ y $(L,t)$ se entiende que se habla de derivadas laterales.

\begin{proposition}
    Sea $u \in \mathcal{C}^2((0,L) \times (0,T)) \cap \mathcal{C}^{0,1}([0,L] \times [0,T])$ una solución de \textup{(PMD)} o de \textup{(PMN)}, y sea $E^{(u)} \colon [0,T] \to \R$ la función definida por
    \[E^{(u)}(t) = \frac{1}{2}\int_0^L(u_t(x,t)^2+c^2u_x(x,t)^2) \, dx.\]
    Entonces $E^{(u)}$ es constante.
\end{proposition}

\begin{proof}
    Se justifica fácilmente que el teorema de derivación bajo el signo integral es válido en estas circunstancias, así que para todo $t \in [0,T]$ se tiene que
    \begin{align*}
        (E^{(u)})'(t) &= \frac{1}{2}\int_0^L(2u_t(x,t)u_{tt}(x,t)+2c^2u_x(x,t)u_{xt}(x,t)) \, dx \\
        &= \int_0^Lu_t(x,t)u_{tt}(x,t)\, dx +\int_0^Lc^2u_x(x,t)u_{xt}(x,t) \, dx \\
        &= \int_0^Lu_t(x,t)u_{tt}(x,t)\, dx +\int_0^Lc^2u_x(x,t)u_{tx}(x,t) \, dx. \tag{$\ast$}
    \end{align*}
    Integrando por partes,
    \[\int_0^L c^2u_x(x,t)u_{tx}(x,t) \, dx = c^2\biggl[u_x(x,t)u_t(x,t)\biggr]_{x=0}^{x=L} -\int_0^Lc^2u_{xx}(x,t)u_t(x,t) \, dx.\]
    Ahora bien, si $u$ es solución de (PMD), entonces
    \[u(0,t) = u(L,t) = 0,\]
    y por tanto, al derivar se obtiene
    \[u_t(0,t) = u_t(L,t) = 0.\]
    Y si $u$ es solución de (PMN), entonces
    \[u_x(0,t) = u_x(L,t) = 0.\]
    En cualquier caso,
    \[\biggl[u_x(x,t)u_t(x,t)\biggr]_{x=0}^{x=L}  = 0,\]
    luego 
    \[\int_0^L c^2u_x(x,t)u_{tx}(x,t) \, dx = -\int_0^Lc^2u_{xx}(x,t)u_t(x,t) \, dx.\]
    Llevando esto a $(\ast)$,
    \[(E^{(u)})'(t) = \int_0^Lu_t(x,t)(u_{tt}(x,t)-c^2u_{xx}(x,t)) \, dx = 0,\]
    así que $E^{(u)}$ es constante.
\end{proof}

\begin{theorem}
    Los problemas \textup{(PMD)} y \textup{(PMN)} tienen, a lo sumo, una solución.
\end{theorem}

\begin{proof}
    Sean $u$ y $v$ dos soluciones de, por ejemplo, (PMD). Entonces $w = u-v$ verifica
    \[
         \left\{\begin{alignedat}{5}
            w_{tt}(x,t)-c^2w_{xx}(x,t) &= 0, \qquad & x &\in (0,L), \ & t &\in (0,T), \\
            w(x,0) &= 0, \qquad & x &\in [0,L], & & \\
            w_t(x,0) &= 0, \qquad & x &\in [0,L], & & \\
            w(0,t) &= 0, \qquad & & & t &\in [0,T], \\
            w(L,t) &= 0, \qquad & & & t &\in [0,T],
        \end{alignedat}\right.
    \]
    o sea, $w$ es solución de (PMD) con $u_0 = u_1 = 0$. Por la proposición anterior, $E^{(w)}$ es constante. Como
    \[E^{(w)}(t) = \frac{1}{2}\int_0^L(w_t(x,t)^2+c^2w_x(x,t)^2) \, dx,\]
    entonces
    \[E^{(w)}(0) = \frac{1}{2}\int_0^L(w_t(x,0)^2+c^2w_x(x,0)^2) \, dx,\]
    Pero $w_t(x,0) = 0$ y $w_x(x,0) = 0$ para todo $x \in [0,L]$, luego $E^{(w)}(0) = 0$ y por tanto $E^{(w)}(t) = 0$ para todo $t \in [0,T]$. Como el integrando de $E^{(w)}$ es no negativo, debe ser
    \[w_t(x,t)^2+c^2w_x(x,t)^2 = 0\]
    para todo $(x,t) \in [0,L] \times [0,T]$, luego $w_t(x,t) = 0$ y $w_x(x,t) = 0$ para todo $(x,t) \in [0,L] \times [0,T]$. Por tanto, $w$ es constante; constante 0 porque $w(0,t) = 0$ para todo $t \in [0,T]$.

    La conclusión es que $w = 0$ y, en consecuencia, que $u = v$, concluyéndose que (PMD) tiene a lo sumo una solución. Para el problema (PMN) se razona de forma totalmente análoga.
\end{proof}

Estudiar la existencia de soluciones de los problemas (PMD) o (PMN) va a llevar bastante más trabajo. Primero se va a trabajar con el problema (PMD).

La idea es buscar una solución $w \colon [0,L] \times [0,T] \to \R$ de la ecuación ($\textup{O}_h$) que sea no nula y que tenga las variables separadas, es decir, que sea de la forma
\[w(x,t) = S(t)v(x).\]
Sea $(x,t) \in (0,T) \times (0,L)$. Se tiene que
\[w_{tt}(x,t)-c^2w_{xx}(x,t) = 0 \iff S''(t)v(x)-c^2S(t)v''(x) = 0.\]
Si fuese $v(x) \neq0$ y $S(t) \neq 0$, entonces
\[S''(t)v(x)-c^2S(t)v''(x) = 0 \iff \frac{S''(t)}{c^2S(t)} = \frac{v''(x)}{v(x)}.\]
Como $\frac{v''(x)}{v(x)}$ no depende de $t$, entonces $\frac{S''(t)}{S(t)}$ tampoco, luego
\begin{align*}
    S''(t)v(x)-c^2S(t)v''(x) = 0 &\iff \exists \ \lambda \in \R \textup{ tal que } \lambda = \frac{S''(t)}{c^2S(t)} = \frac{v''(x)}{v(x)} \\[10pt]
    &\iff  \exists \ \lambda \in \R \textup{ tal que } \begin{cases}
        S''(t) - \lambda c^2S(t) = 0, \\
        v''(x) - \lambda v(x) = 0.
    \end{cases}
\end{align*}
Ahora bien, la afirmación
\[S''(t)v(x)-c^2S(t)v''(x) = 0 \iff \exists \ \lambda \in \R \textup{ tal que } \begin{cases}
    S''(t) - \lambda c^2S(t) = 0, \\
    v''(x) - \lambda v(x) = 0.
\end{cases}\]
sigue siendo cierta incluso si $v(x) = 0$ o $S(t) = 0$. En resumen,
\[w_{tt}(x,t)-c^2w_{xx}(x,t) = 0 \iff \exists \ \lambda \in \R \textup{ tal que } \begin{cases}
    S''(t) - \lambda c^2S(t) = 0, \\
    v''(x) - \lambda v(x) = 0.
\end{cases}\]
Respecto a las condiciones de Dirichlet homogéneas,
\[w(0,t) = 0 \iff S(t)v(0) = 0, \qquad \qquad w(L,t) = 0 \iff S(t)v(L) = 0,\]
y como $S$ no es idénticamente nula,
\[w(0,t) = 0 \iff v(0) = 0, \qquad \qquad w(L,t) = 0 \iff v(L) = 0.\]
Lo que hay que hacer ahora es resolver el problema
\[(\ast) \ \left\{\begin{alignedat}{2}
    v''(x)-\lambda v(x) &= 0, \qquad &x \in (0,L),\\
    v(0) &= 0,& \\
    v(L) &= 0.&
\end{alignedat}\right.\]
El polinomio característico de la ecuación es $y^2-\lambda$, y sus raíces dependen del signo de $\lambda$.
\begin{itemize}
    \item Si $\lambda > 0$, las raíces del polinomio característico son $\sqrt{\lambda}$ y $-\sqrt{\lambda}$, así que la solución de la ecuación viene dada por
    \[v(x) = Ae^{\sqrt{\lambda}x}+Be^{-\sqrt{\lambda}x}, \qquad x \in [0,L],\]
    con $A,B \in \R$ constantes. Además,
    \[\left\{\begin{alignedat}{2}
        v(0) &= 0 \\
        v(L) &= 0
    \end{alignedat}\right. \iff \left\{\begin{alignedat}{2}
        A+B &= 0 \\
        Ae^{\sqrt{\lambda}L}+Be^{-\sqrt{\lambda}L} &= 0
    \end{alignedat}\right. \iff \left\{\begin{alignedat}{2}
        A+B &= 0 \\
        B &= -Ae^{2\sqrt{\lambda} L}
    \end{alignedat}\right.\]
    La primera ecuación es entonces $A(1-e^{2\sqrt{\lambda}L}) = 0$. Pero $e^{2\sqrt{\lambda}L} \neq 0$ al ser $2\sqrt{\lambda}L \neq 0$, luego $A = 0$ y por tanto $B = 0$. La conclusión de este caso es que $v = 0$.
    \item Si $\lambda = 0$, la única raíz del polinomio característico es $0$, así que la solución de la ecuación viene dada por
    \[v(x) = A+Bt, \qquad x \in [0,L],\]
    con $A,B \in \R$ constantes. Además,
    \[\left\{\begin{alignedat}{2}
        v(0) &= 0 \\
        v(L) &= 0
    \end{alignedat}\right. \iff \left\{\begin{alignedat}{2}
        A &= 0 \\
        A+BL &= 0
    \end{alignedat}\right. \iff \left\{\begin{alignedat}{2}
        A &= 0 \\
        B &= 0
    \end{alignedat}\right.\]
    La conclusión de este caso también es $v = 0$.
    \item Si $\lambda < 0$, las raíces del polinomio característico son $i\sqrt{-\lambda}$ y $-i\sqrt{-\lambda}$, así que la solución de la ecuación viene dada por
    \[v(x) = A\cos(\sqrt{-\lambda} x)+B\sen(\sqrt{-\lambda} x), \qquad x \in [0,L],\]
    con $A,B \in \R$ constantes. Además,
    \[\left\{\begin{alignedat}{2}
        v(0) &= 0 \\
        v(L) &= 0
    \end{alignedat}\right. \iff \left\{\begin{alignedat}{2}
        A &= 0 \\
        A\cos(\sqrt{-\lambda} L)+B\sen(\sqrt{-\lambda} L) &= 0
    \end{alignedat}\right. \iff \left\{\begin{alignedat}{2}
        A &= 0 \\
        \sqrt{-\lambda}L &= k\pi, \ k \in \Z
    \end{alignedat}\right.\]
    Por tanto,
    \[v(x) = B\sen\left(\frac{k\pi}{L}x\right), \qquad x \in [0,L],\]
    para cualquier constante $B \in \R$ y para cualquier $k \in \Z$. La conclusión de este caso es que el problema tiene infinitas soluciones no nulas.
\end{itemize}

Esto prueba que el problema $(\ast)$ tiene soluciones no triviales si y solo si $\sqrt{-\lambda}L=k\pi$ para cualquier $k \in \Z$ con $k \neq 0$, es decir, si y solo si
\[\lambda = -\frac{k^2\pi^2}{L^2}\]
para cualquier $k \in \N$. En ese caso, las soluciones de dicho problema vienen dadas por
\[v_k(x) = \sen\left(\frac{k\pi}{L}x\right), \qquad x \in [0,L],\]
o cualquier múltiplo. Ahora se resuelve la ecuación
\[S''(t)-\lambda c^2S(t) = 0,\]
para los valores de $\lambda$ adecuados, es decir, se resuelve 
\[S''_k(t) +\frac{k^2\pi^2}{L^2}c^2 S_k(t) = 0\]
para cada $k \in \N$. El polinomio característico es $y^2+\frac{k^2\pi^2}{L^2}c^2$, cuyas raíces son $i\frac{k\pi}{L}c$ y $-i\frac{k\pi}{L}c$. Por tanto,
\[S_k(t) = A_k\cos\left(\frac{k\pi}{L}ct\right)+B_k\sen\left(\frac{k\pi}{L}ct\right), \qquad t \in [0,T],\]
donde $A_k,B_k \in \R$ son constantes cualesquiera. Se recopila lo obtenido hasta ahora en forma de proposición.

\begin{proposition}
    Sean $\{A_k\}_{k=1}^\infty$ y $\{B_k\}_{k=1}^\infty$ sucesiones de números reales. Para cada $k \in \N$, la función $w_k \colon [0,L] \times [0,T] \to \R$ dada por
    \[w_k(x,t) = \left(A_k\cos\left(\frac{k\pi}{L}ct\right)+B_k\sen\left(\frac{k\pi}{L}ct\right)\right)\sen\left(\frac{k\pi}{L}x\right)\]
    es de $\mathcal{C}^2((0,L) \times (0,T)) \cap \mathcal{C}^{0,1}([0,L] \times [0,T])$ y verifica lo siguiente:
    \[
        \left\{\begin{alignedat}{5}
            (w_k)_{tt}(x,t)-c^2(w_k)_{xx}(x,t) &= 0, \qquad & x &\in (0,L), \ & t &\in (0,T), \\
            w_k(0,t) &= 0, \qquad & & & t &\in [0,T], \\
            w_k(L,t) &= 0, \qquad & & & t &\in [0,T].
        \end{alignedat}\right.
    \]
\end{proposition}

Para cada $k \in \N$, la función $w_k$ del resultado anterior está muy cerca de resolver (PMD): solo falta que se cumpla
\[w_k(x,0) = u_0(x), \qquad w_t(x,0) = u_1(x),\]
para todo $x \in [0,L]$, y para ello, habrá que escoger $A_k$ y $B_k$ adecuadamente. Se tiene que
\[w_k(x,0) = A_k\sen\left(\frac{k\pi}{L}x\right), \qquad w_t(x,0) = \frac{k\pi}{L}cB_k\sen\left(\frac{k\pi}{L}x\right).\]
Ahora bien, ¿existen $A_k, B_k \in \R$ tales que
\[A_k\sen\left(\frac{k\pi}{L}x\right) = u_0(x)\qquad \textup{y} \qquad \frac{k\pi}{L}cB_k\sen\left(\frac{k\pi}{L}x\right) = u_1(x)\]
para todo $x \in [0,L]$? La respuesta, en general, es negativa; basta tomar $u_0$ y $u_1$ constantes y no nulos. Por tanto, las funciones $w_k$ no sirven para resolver (PMD), pero quizá sí sirva una suma finita de dichas funciones...

\begin{proposition}
    Sean $\{A_k\}_{k=1}^\infty$ y $\{B_k\}_{k=1}^\infty$ sucesiones de números reales. Para cada $n \in \N$, la función $u^{(n)} \colon [0,L] \times [0,T] \to \R$ dada por
    \[u^{(n)}(x,t)=\sum_{k=1}^n w_k(x,t) = \sum_{k=1}^n\left(A_k\cos\left(\frac{k\pi}{L}ct\right)+B_k\sen\left(\frac{k\pi}{L}ct\right)\right)\sen\left(\frac{k\pi}{L}x\right)\]
    es de $\mathcal{C}^2((0,L) \times (0,T)) \cap \mathcal{C}^{0,1}([0,L] \times [0,T])$ y verifica lo siguiente:
    \[
        \left\{\begin{alignedat}{5}
            u^{(n)}_{tt}(x,t)-c^2u^{(n)}_{xx}(x,t) &= 0, \qquad & x &\in (0,L), \ & t &\in (0,T), \\
            u^{(n)}(0,t) &= 0, \qquad & & & t &\in [0,T], \\
            u^{(n)}(L,t) &= 0, \qquad & & & t &\in [0,T].
        \end{alignedat}\right.
    \]
\end{proposition}

\begin{proof}
    Inmediata.
\end{proof}

De nuevo, las funciones $u^{(n)}$ están cerca de resolver el problema (PMD), pero falta que se verifique
\[u^{(n)}(x,0) = u_0(x), \qquad u^{(n)}(x,0) = u_1(x)\]
para todo $x \in [0,L]$. Ahora la pregunta que se plantea es la siguiente: ¿existen $\{A_k\}_{k=1}^n$ y $\{B_k\}_{k=1}^n$ tales que
\[\sum_{k=1}^n A_k\sen\left(\frac{k\pi}{L}x\right) = u_0(x)\qquad \textup{y} \qquad \sum_{k=1}^n\frac{k\pi}{L}cB_k\sen\left(\frac{k\pi}{L}x\right) = u_1(x)\]
para todo $x \in [0,L]$? La respuesta a esta pregunta ya no es tan directa como antes. Es más, como $n$ es un número natural arbitrario, resulta natural preguntarse: ¿existen $\{A_k\}_{k=1}^\infty$ y $\{B_k\}_{k=1}^\infty$ tales que
\[\sum_{k=1}^\infty A_k\sen\left(\frac{k\pi}{L}x\right) = u_0(x)\qquad \textup{y} \qquad \sum_{k=1}^\infty\frac{k\pi}{L}cB_k\sen\left(\frac{k\pi}{L}x\right) = u_1(x)\]
para todo $x \in [0,L]$? En caso afirmativo, ¿la función $u \colon [0,L] \times [0,T] \to \R$ dada por
\[u(x,t) = \sum_{k=1}^\infty\left(A_k\cos\left(\frac{k\pi}{L}ct\right)+B_k\sen\left(\frac{k\pi}{L}ct\right)\right)\sen\left(\frac{k\pi}{L}x\right),\]
en caso de que esté bien definida, será solución de (PMD)? 

Todas estas preguntas se responden en el \hyperref[A]{\color{gray}Apéndice A}: los $A_k$ deben ser los coeficientes de Fourier de la serie de senos de $u_0$, es decir,
\[A_k = b_k(u_0) = \frac{2}{L}\int_0^L u_0(x)\sen\left(\frac{k\pi}{L}x\right) \, dx,\]
para cada $k \in \N$, mientras que los $\frac{k\pi}{L}cB_k$ deben coincidir con los coeficientes de Fourier de la serie de senos de $u_1$, es decir,
\[B_k = \frac{L}{k\pi c}b_k(u_1) = \frac{2}{k\pi c}\int_0^L u_1(x)\sen\left(\frac{k\pi}{L}x\right) \, dx,\]
para cada $k \in \N$. La pregunta que queda por responder es si la función $u \colon [0,L] \times [0,T] \to \R$ dada por
\[u(x,t) = \sum_{k=1}^\infty\left(b_k(u_0)\cos\left(\frac{k\pi}{L}ct\right)+\frac{L}{k\pi c}b_k(u_1)\sen\left(\frac{k\pi}{L}ct\right)\right)\sen\left(\frac{k\pi}{L}x\right),\]
está bien definida, y, en ese caso, si es solución de (PMD). La respuesta se halla en el siguiente resultado, cuya demostración va a ser omitida:

\begin{theorem}
    Si $u_0 \in \mathcal{C}^2([0,L])$, $u_1 \in \mathcal{C}^1([0,L])$ y se verifica
    \[u_0(0)=u_0(L)=0, \qquad u_0''(0)=u_0''(L)= 0, \qquad u_1(0)=u_1(L)=0,\]
    entonces la función $u \colon [0,L] \times [0,T] \to \R$ dada por
    \[u(x,t) = \sum_{k=1}^\infty\left(b_k(u_0)\cos\left(\frac{k\pi}{L}ct\right)+\frac{L}{k\pi c}b_k(u_1)\sen\left(\frac{k\pi}{L}ct\right)\right)\sen\left(\frac{k\pi}{L}x\right)\]
    es solución de $(\textup{PMD})$.
\end{theorem}

Respecto al problema (PMN), unos razonamientos análogos a los anteriores deben desembocar en un teorema similar.

\section{Método de separación de variables}

Esta idea de buscar soluciones de la forma $w(x,t) = S(t)v(x)$ puede ser de utilidad en problemas diferentes los estudiados en la sección anterior.

Sean $p \in \mathcal{C}^1([a,b])$, $u_0, q,r \in \mathcal{C}([a,b])$ y $\alpha_1,\alpha_2,\beta_1,\beta_2 \in \R$. Supóngase que $q(t) > 0$ y $r(t) > 0$ para todo $t \in [a,b]$ y que $(\alpha_1,\alpha_2)\neq (0,0)$ y $(\beta_1,\beta_2)\neq (0,0)$. Considérese el problema
\[
        \left\{\begin{alignedat}{5}
            r(x)u_{t}(x,t)-(p(x)u_x(x,t)) _x = q(x)u(x,t) &= 0, \qquad & x &\in (a,b), \ & t &>0, \\
            u(x,0) &= u_0(x), \qquad & x &\in [a,b], & & \\
            \alpha_1u(a,t)+\alpha_2u_x(a,t) &= 0, \qquad & & & t &> 0, \\
            \beta_1u(b,t)+\beta_2u_x(b,t) &= 0, \qquad & & & t &> 0.
        \end{alignedat}\right.
\]

El objetivo es hallar una solución formal del problema, o sea, conjeturar cuál sería una candidata a resolver el problema. El \emph{método de separación de variables} es el siguiente:
\begin{itemize}
    \item Se buscan soluciones de la ecuación de la forma $w(x,t) = S(t)v(x)$, $x \in [a,b]$, $t \geq 0$, que sean no nulas y que satisfagan 
    \[\alpha_1u(a,t)+\alpha_2u_x(a,t) = 0, \qquad \beta_1u(b,t)+\beta_2u_x(b,t) = 0,\]
    para todo $t > 0$. Para que esto se verifique, se comprueba fácilmente que $v$ debe ser solución del problema
    \[
        (\textup{P}_\lambda) \ \left\{\begin{alignedat}{5}
            (p(x)v'(x))'+q(x)v(x) &= \lambda r(x)v(x), \qquad & x &\in (a,b), \\
            \alpha_1v(a)+\alpha_2v'(a) &= 0, \\
            \beta_1v(b)+\beta_2v'(b) &= 0,
        \end{alignedat}\right.
    \]
    para algún $\lambda \in \R$, mientras que $S$ debe ser solución de la ecuación
    \[S'(t) = \lambda S(t), \qquad t >0,\]
    con el mismo $\lambda \in \R$ del problema anterior.
    \item Por un resultado que no se va a enunciar ni probar, existe una sucesión $\{\lambda_k\}_{k=1}^\infty$ de números reales de forma que para cada $k \in \N$, el problema $(\textup{P}_{\lambda_k})$ tiene solución no nula, llámese $v_k$.
    \item Para cada $k \in \N$, se resuelve la ecuación
    \[S'(t) = \lambda_k S(t), \qquad t > 0,\]
    obteniéndose
    \[S(t) = ce^{\lambda_kt}, \qquad t > 0,\]
    para cualquier constante $c \in \R$. En consecuencia, 
    \[w_k(x,t) = cv_k(x)e^{\lambda_kt}, \qquad x \in [a,b], \ t \geq 0,\] para cualquier constante $c \in \R$.
    \item Se busca una función $u \colon [a,b] \times [0,\infty) \to \R$ de la forma
    \[u(x,t) = \sum_{k=1}^\infty S_k(t)v_k(x)\]
    que satisfaga
    \[u(x,0) = u_0(x), \qquad x \in [a,b],\]
    es decir,
    \[u_0(x) = \sum_{k=1}^\infty S_k(0)v_k(x), \qquad x\in [a,b].\]
\end{itemize}

Al finalizar esta receta, la función $u$ anterior es la candidata a solución. Faltaría probar que está bien definida, que disfruta de la regularidad necesaria, que realmente satisface la ecuación y el resto de condiciones... pero eso es harina de otro costal.

\chapter{Ecuación del calor}

\begin{definition}
    Sea $\Omega \subset \R^n$ un abierto, sea $T \in \R$ con $0 < T \leq \infty$, sea $c \in \R$ y sea $F \in \mathcal{C}(\Omega \times (0,T))$. La \emph{ecuación del calor} es
    \[u_{t}(x,t) - c^2\Delta_xu(x,t) = F(x,t), \qquad x \in \Omega, \ t \in (0,T),\]
    donde $\Delta_xu(x,t) = u_{x_1x_1}(x,t)+u_{x_2x_2}(x,t)+\mathellipsis+u_{x_nx_n}(x,t)$. Si $F = 0$, se habla de \emph{ecuación del calor homogénea}.
\end{definition}

Esta ecuación sirve para modelar la conducción del calor en un cuerpo (por ejemplo, en dimensión 1, una varilla de metal). Si $u$ resuelve la ecuación anterior, el número real $u(x,t)$ es la temperatura del punto $x$ de dicho cuerpo en el instante $t$.

\section{Problemas mixtos asociados a la ecuación del calor}

En esta sección se va a estudiar la ecuación del calor homogénea con $c = 1$ en $\Omega \times (0,T)$, siendo $\Omega \subset \R^n$ un dominio acotado y $T \in (0,\infty)$. Es decir, la ecuación a considerar es
\[u_{t}(x,t) - \Delta_xu(x,t) = 0, \qquad x \in \Omega, \ t \in (0,T).\]
Además, por comodidad, se denotará $\Omega_T = \Omega \times (0,T)$. Nótese que entonces $\overline{\Omega_T} = \overline{\Omega} \times [0,T]$ y que $\overline{\Omega}$ es un compacto de $\R^n$ por ser $\Omega$ un dominio acotado.

\begin{definition}
    Sea $\Omega \subset \R^n$ un dominio acotado, sea $T \in (0,\infty)$ y sea $F \in \mathcal{C}(\Omega_T)$. Considérese la ecuación
    \[u_{t}(x,t) - \Delta_xu(x,t) = F(x,t), \qquad x \in \Omega, \ t \in (0,T), \tag{C}\]
    y sean $u_0 \in \mathcal{C}(\overline{\Omega})$ y $\varphi \in \mathcal{C}(\partial\Omega \times [0,T])$. Se llama \emph{problema mixto de Dirichlet asociado a $\textup{(C)}$ con datos $u_0$ y $\varphi$} al problema que consiste en hallar $u \in \mathcal{C}^{2,1}(\Omega_T) \cap \mathcal{C}(\overline{\Omega_T})$ tal que
    \[
        \left\{\begin{alignedat}{5}
            u_{t}(x,t)-\Delta_xu(x,t) &= F(x,t), \qquad & x &\in \Omega, \ & t &\in (0,T), \\
            u(x,0) &= u_0(x), \qquad & x &\in \Omega, & & \\
            u(x,t) &= \varphi(x,t), \qquad & x &\in \partial\Omega, \ & t &\in [0,T]. \\
        \end{alignedat}\right.
    \]
    En este contexto, la condición
    \[u(x,t) = \varphi(x,t), \qquad  x \in \partial\Omega, \  t \in [0,T],\]
    se denomina \emph{condición de frontera de Dirichlet}.
\end{definition}

Lo primero que se va a tratar de demostrar es que el problema anterior tiene, a lo sumo, una solución. Para ello, se necesitan unos cuantos resultados previos.

\begin{definition}
    Sea $\Omega \subset \R^n$ un dominio acotado y sea $T\in (0,\infty)$. Se define la \emph{frontera parabólica de $\Omega_T$} como
    \[\partial_p\Omega_T = (\overline{\Omega} \times \{0\}) \cup (\partial \Omega \times [0,T]).\]
\end{definition}

\begin{theorem}[Principio del máximo para la ecuación del calor]
    Sea $\Omega \subset \R^n$ un dominio acotado, sea $T \in (0,\infty)$ y sea $u \in \mathcal{C}^{2,1}(\Omega_T) \cap \mathcal{C}(\overline{\Omega_T})$ tal que
    \[u_t(x,t)-\Delta_xu(x,t) \leq 0\]
    para todo $(x,t) \in \Omega_T$. Entonces
    \[\max_{(x,t)\in \overline{\Omega_T}} u(x,t) = \max_{(x,t) \in \partial_p\Omega_T}u(x,t).\]
\end{theorem}

\begin{proof}
    Lo primero de todo es observar que los máximos anteriores existen porque $u$ es continua en los compactos $\overline{\Omega_T}$ y $\partial_p\Omega_T$ de $\R^{n+1}$. Se distinguen dos casos:
    \begin{itemize}
        \item Supongamos que $u_t(x,t)-\Delta_xu(x,t) < 0$ para todo $(x,t) \in \Omega_T$. Sea $\varepsilon > 0$ y veamos que
        \[\max_{(x,t)\in \overline{\Omega_{T-\varepsilon}}} u(x,t) = \max_{(x,t) \in \partial_p\Omega_{T-\varepsilon}}u(x,t).\]
        Sea $(x_0,t_0) \in \overline{\Omega_{T-\varepsilon}}$ tal que
        \[u(x_0,t_0) = \max_{(x,t)\in \overline{\Omega_{T-\varepsilon}}} u(x,t).\]
        Si fuese $(x_0,t_0) \in \Omega_{T-\varepsilon}$, entonces el teorema del extremo interior aplicado a la función $t \mapsto u(x_0,t)$, $t \in (0,T)$, diría que $u_t(x_0,t_0)=0$.
        Por otra parte, la función $x \mapsto u(x,t_0)$, $x \in \Omega$, alcanza el máximo en $x_0$, así que la matriz hessiana de esta función en $x_0$ es semidefinida negativa, y en consecuencia, $u_{x_ix_i}(x_0,t_0) \leq 0$ para todo $i \in \{1,\mathellipsis,n\}$. Por tanto, $\Delta_xu(x_0,t_0) \leq$, de donde se obtiene $u_t(x_0,t_0)-\Delta_xu(x_0,t_0) \geq 0$, que es una contradicción. Se tiene entonces que $(x_0,t_0) \not\in \Omega_{T-\varepsilon}$.

        También se cumple que $(x_0,t_0) \not\in \Omega \times \{T-\varepsilon\}$, pues en caso contrario (o sea, si $x_0 \in \Omega$ y $t_0=T-\varepsilon$) se tendría, razonando como antes, que $\Delta_xu(x_0,t_0) \leq 0$, y además,
        \[u_t(x_0,T-\varepsilon) = \lim_{t \to (T-\varepsilon)^{-}} \frac{u(x_0,t) - u(x_0,T-\varepsilon)}{t-(T-\varepsilon)} \geq 0,\]
        pues en este último cociente tanto numerador como denominador son negativos. Tenemos de nuevo $u_t(x_0,t_0)-\Delta_xu(x_0,t_0) \geq 0$, que es una contradicción.

        Recapitulando, se tiene que 
        \[(x_0,t_0) \in \overline{\Omega_{T-\varepsilon}} = \overline{\Omega} \times [0,T-\varepsilon], \qquad (x_0,t_0) \not\in \Omega \times (0,T-\varepsilon), \qquad (x_0,t_0) \not\in \Omega \times \{T-\varepsilon\}.\]
        Si fuese $x_0 \in \Omega$, entonces $t_0 \not\in (0,T-\varepsilon]$, luego $t_0 = 0$ y por tanto $(x_0,t_0) \in \overline{\Omega} \times \{0\}$. Y si fuese $x_0 \not\in \Omega$, entonces $x_0 \in \overline{\Omega} \setminus \Omega = \partial \Omega$ y por tanto $(x_0,t_0) \in \partial\Omega \times [0,T-\varepsilon]$. En cualquier caso, $(x_0,t_0) \in \partial_p\Omega_{T-\varepsilon}$, lo que prueba que
        \[\max_{(x,t)\in \overline{\Omega_{T-\varepsilon}}} u(x,t) = \max_{(x,t) \in \partial_p\Omega_{T-\varepsilon}}u(x,t).\]
        Una vez probado esto, es fácil quitar $\varepsilon$ de en medio, pues para todo $(x_0,t_0) \in \overline{\Omega} \times [0,T)$ existe $\varepsilon > 0$ tal que $(x,t) \in \overline{\Omega} \times [0,T-\varepsilon] = \overline{\Omega_{T-\varepsilon}}$, y usando lo anterior,
        \[u(x_0,t_0) \leq \max_{(x,t)\in \overline{\Omega_{T-\varepsilon}}} u(x,t) = \max_{(x,t) \in \partial_p\Omega_{T-\varepsilon}}u(x,t) \leq \max_{(x,t) \in \partial_p\Omega_T}u(x,t).\]
        Como $u$ es continua en $\overline{\Omega_T}$, esto debe tenerse también para $t_0 = T$, luego
        \[u(x_0,t_0) \leq  \max_{(x,t) \in \partial_p\Omega_T}u(x,t)\] 
        para todo $(x_0,t_0) \in \overline{\Omega_T}$, y por tanto
        \[\max_{(x,t) \in\overline{\Omega_T}}u(x,t) = \max_{(x,t) \in \partial_p\Omega_T}u(x,t).\]
        \item Supongamos ahora que $u_t(x,t)-\Delta_xu(x,t) \leq 0$ para todo $(x,t) \in \Omega_T$. Sea $K > 0$ y sea $v \colon \overline{\Omega_T} \to \R$ la función dada por
        \[v(x,t)=u(x,t)-Kt,\]
        que satisface
        \[v_t(x,t)-\Delta_xv(x,t) = u_t(x,t)-\Delta_xu(x,t)-K < 0\]
        para todo $(x,t) \in \Omega_T$, y se puede usar lo probado anteriormente para obtener
        \[\max_{(x,t) \in \overline{\Omega_T}}u(x,t) \leq \max_{(x,t) \in \overline{\Omega_T}}v(x,t)+KT = \max_{(x,t) \in \partial_p \Omega_T}v(x,t)+KT \leq \max_{(x,t) \in \partial_p \Omega_T}u(x,t)+KT.\]
        Al ser esto válido para todo $K>0$, se tiene que
        \[\max_{(x,t) \in \overline{\Omega_T}}u(x,t) \leq \max_{(x,t) \in \partial_p \Omega_T}u(x,t).\]
        Teniendo en cuenta que $\partial_p\Omega_T \subset \overline{\Omega_T} $, se concluye que
        \[\max_{(x,t) \in \overline{\Omega_T}}u(x,t) = \max_{(x,t) \in \partial_p \Omega_T}u(x,t). \qedhere\]
    \end{itemize}
\end{proof}

\begin{corollary}[Principio del mínimo para la ecuación del calor]
    Sea $\Omega \subset \R^n$ un dominio acotado, sea $T \in (0,\infty)$ y sea $u \in \mathcal{C}^{2,1}(\Omega_T) \times \mathcal{C}(\overline{\Omega_T})$ tal que
    \[u_t(x,t)-\Delta_xu(x,t) \geq 0\]
    para todo $(x,t) \in \Omega_T$. Entonces
    \[\min_{(x,t)\in \overline{\Omega_T}} u(x,t) = \min_{(x,t) \in \partial_p\Omega_T}u(x,t).\]
\end{corollary}

\begin{proof}
    Aplíquese el resultado anterior a $-u$.
\end{proof}

\begin{corollary}
    Sea $\Omega \subset \R^n$ un dominio acotado, sea $T \in (0,\infty)$ y sea $u \in \mathcal{C}^{2,1}(\Omega_T) \times \mathcal{C}(\overline{\Omega_T})$ tal que
    \[u_t(x,t)-\Delta_xu(x,t) = 0\]
    para todo $(x,t) \in \Omega_T$. Entonces
    \[\max_{(x,t)\in \overline{\Omega_T}} |u(x,t)| = \max_{(x,t) \in \partial_p\Omega_T}|u(x,t)|.\]
\end{corollary}

\begin{proof}
    Aplíquense los dos resultados anteriores teniendo en cuenta que para cualquier subconjunto $D \subset \R^n$ y cualquier función $f \colon D \to \R$ que alcance el máximo y el mínimo, se verifica
    \[\max_{x \in D} |f(x)| = \max\left\{\max_{x \in D}f(x),-\min_{x \in D}f(x)\right\}. \qedhere\]
\end{proof}

\begin{theorem}
    El problema mixto de Dirichlet asociado a $\textup{(C)}$ tiene, a lo sumo, una solución. 
\end{theorem}

\begin{proof}
    Si $u_1$ y $u_2$ resolvieran dicho problema, entonces $u = u_1-u_2$ verificaría las hipótesis del corolario anterior y se anularía en la frontera parabólica, obteniéndose que $u = 0$, o sea, $u_1=u_2$.
\end{proof}

Pasamos a estudiar la existencia de soluciones para el problema mixto de Dirichlet asociado a la ecuación del calor homogénea. Se va a tomar $n = 1$ y las condiciones en la frontera se van a considerar homogéneas. Los dominios acotados de $\R$ no son más que intervalos abiertos de extremos finitos, así que el problema a resolver es el de hallar $u \in \mathcal{C}^{2,1}((0,L) \times (0,T)) \cap \mathcal{C}([0,L] \times [0,T])$ tal que
\[
    (\textup{PM1}) \ \left\{\begin{alignedat}{5}
        u_{t}(x,t)-u_{xx}(x,t) &= 0, \qquad & x &\in (0,L), \ & t &\in (0,T), \\
        u(x,0) &= u_0(x), \qquad & x &\in [0,L], & & \\
        u(0,t) &= 0, \qquad & & & t &\in [0,T], \\
        u(L,t) &= 0, \qquad & & & t &\in [0,T], \\
    \end{alignedat}\right.
\]
donde $u_0 \in \mathcal{C}([0,L])$. La idea es emplear el método de separación de variables. Razonando como en la resolución del problema mixto asociado a la ecuación de ondas, se obtiene que una función $w \colon [0,L] \times [0,T] \to \R$ de la forma $w(x,t)=v(x)S(t)$ es solución no nula de la ecuación del calor homogénea (y además cumple las condiciones en los extremos) si para cualquier $\lambda \in \R$, $v$ es solución del problema 
\[\left\{\begin{alignedat}{1}
    v''(x)-\lambda v(x) &= 0, \qquad x \in (0,L),\\
    v(0)&=0,\\
    v(L)&=0,
\end{alignedat}\right.\]
y $S$ es solución de la ecuación
\[S'(t) -\lambda S(t) = 0, \qquad t \in (0,T).\]

El problema para $v$ es el mismo que apareció con la ecuación de ondas: lo que se obtuvo fue que el problema para $v$ tiene soluciones no nulas si y solo si $\lambda = -\frac{k^2\pi^2}{L^2}$ para cualquier $k \in \N$, en cuyo caso la solución es
\[v_k(x) = \sen\left(\frac{k\pi}{L}x\right), \qquad x \in [0,L],\]
o cualquier múltiplo suyo.

Por otro lado, la ecuación para $S$ es extremadamente fácil de resolver: para cada $k \in \N$, la solución de la ecuación
\[S'(t) +\frac{k^2\pi^2}{L^2} S(t) = 0, \qquad t \in (0,T),\]
no es más que
\[S_k(t) = A_ke^{-\frac{k^2\pi^2}{L^2}t}, \qquad t \in (0,T),\]
para cualquier constante $A_k \in \R$. Por tanto, para todo $k \in \N$,
\[w_k(x,t)= A_ke^{-\frac{k^2\pi^2}{L^2}t}\sen\left(\frac{k\pi}{L}x\right), \qquad x\in [0,L], \ t \in [0,T], \]
es solución de la ecuación y verifica las condiciones en los extremos. En consecuencia, para todo $N \in \N$,
\[u^{(N)}(x,t) = \sum_{k=1}^N w_k(x,t) = \sum_{k=1}^N w_k(x,t)= A_ke^{-\frac{k^2\pi^2}{L^2}t}\sen\left(\frac{k\pi}{L}x\right), \qquad x\in [0,L], \ t \in [0,T], \]
es solución de la ecuación y verifica las condiciones en los extremos. Cabe preguntarse entonces si bajo ciertas condiciones puede asegurarse que la función $u \colon [0,L] \times [0,T] \to \R$ dada por
\[u(x,t)= \sum_{k=1}^\infty A_ke^{-\frac{k^2\pi^2}{L^2}t}\sen\left(\frac{k\pi}{L}x\right)\]
es solución de (PM1). La respuesta es afirmativa:

\begin{theorem}
    Si $u_0 \in \mathcal{C}([0,L])$ es de clase $1$ a trozos y verifica
    \[u_0(0) = u_0(L) = 0,\]
    entonces la serie 
    \[\sum_{k=1}^\infty b_k(u_0)e^{-\frac{k^2\pi^2}{L^2}t}\sen\left(\frac{k\pi}{L}x\right)\]
    converge uniformemente en $[0,L] \times [0,T]$, y la función $u \colon [0,L] \times [0,T] \to \R$ dada por
    \[u(x,t) = \sum_{k=1}^\infty b_k(u_0)e^{-\frac{k^2\pi^2}{L^2}t}\sen\left(\frac{k\pi}{L}x\right)\]
    está en $\mathcal{C}^\infty([0,L] \times (0,T)) \cap \mathcal{C}([0,L] \times [0,T))$ y es solución de $\textup{(PM1)}$.
\end{theorem}

Cabe remarcar que el resultado anterior sigue siendo cierto si se cambia $T$ por $\infty$ allá donde corresponda.

Ahora se intenta resolver el problema mixto de Dirichlet asociado a la ecuación del calor no homogénea. Se tomará $n=1$ y se considerarán condiciones homogéneas en todos lados. Es decir, se trata de hallar $u \in \mathcal{C}^{2,1}((0,L) \times (0,T)) \cap \mathcal{C}([0,L] \times [0,T])$ tal que
\[
    \textup{(PM2)} \ \left\{\begin{alignedat}{5}
        u_{t}(x,t)-u_{xx}(x,t) &= F(x,t), \qquad & x &\in (0,L), \ & t &\in (0,T), \\
        u(x,0) &= 0, \qquad & x &\in [0,L], & & \\
        u(0,t) &= 0, \qquad & & & t &\in [0,T], \\
        u(L,t) &= 0, \qquad & & & t &\in [0,T]. \\
    \end{alignedat}\right.
\]
Si $u \colon [0,L] \times [0,T] \to \R$ resolviese $\textup{(PM2)}$, la función $x \mapsto u(x,t)$, $x \in [0,L]$, sería continua para cada $t \in [0,T]$ y por tanto puede calcularse su serie de Fourier de senos (nótese que sus coeficientes de Fourier dependen de $t$). Así, llamando $b_k(t) = b_k(u(\cdot,t))$,
\[u(\cdot,t) \sim \sum_{k=1}^n b_k(t)\sen\left(\frac{k\pi}{L}\, \cdot \,\right),\]
donde
\[b_k(t) = \frac{2}{L}\int_{0}^L u(x,t)\sen\left(\frac{k\pi}{L}x\right) \, dx.\]
Se razona análogamente para $F$, llamando ahora $B_k(t) = b_k(F(\cdot,t))$:
\[F(\cdot,t) \sim \sum_{k=1}^n B_k(t)\sen\left(\frac{k\pi}{L}\, \cdot \,\right),\]
donde
\[B_k(t) = \frac{2}{L}\int_{0}^L F(x,t)\sen\left(\frac{k\pi}{L}x\right) \, dx.\]
Considérese la función $G \colon [0,L] \times [0,T] \to \R$ dada por
\[G(x,t) = u_t(x,t)-u_{xx}(x,t) - F(x,t).\]
Al ser $u$ solución de $\textup{(PM2)}$, se tiene que $ G = 0$, así que para cada $t\in[0,T]$ se tiene que los coeficientes de Fourier de la función $x \mapsto G(x,t)$, $x \in [0,L]$, son nulos. Hallemos estos coeficientes: como
\[0 = b_k(G(\cdot,t)) = b_k(u_t(\cdot,t))-b_k(u_{xx}(\cdot,t))-B_k(t),\]
basta hallar $b_k(u_t(\cdot,t))$ y $b_k(u_{xx}(\cdot,t))$. En primer lugar,
\[b_k(u_t(\cdot,t)) = \frac{2}{L}\int_0^L u_t(x,t)\sen\left(\frac{k\pi}{L}x\right)\, dx = b_k'(t),\]
donde la primera igualdad es cierta por definición y la segunda por el teorema de derivación bajo el signo integral. Por otro lado, integrando por partes dos veces,
\begin{align*}
    b_k(u_{xx}(\cdot,t)) &= \frac{2}{L}\int_0^L u_{xx}(x,t)\sen\left(\frac{k\pi}{L}x\right) \, dx \\
    &=\frac{2}{L}\left(\left[u_x(x,t)\sen\left(\frac{k\pi}{L}x\right)\right]_{x=0}^{x=L}-\frac{k\pi}{L}\int_0^L u_x(x,t)\cos\left(\frac{k\pi}{L}x\right)\, dx\right) \\
    &=-\frac{2k\pi}{L^2}\int_0^L u_x(x,t)\cos\left(\frac{k\pi}{L}x\right)\, dx \\
    &= -\frac{2k\pi}{L^2} \left(\left[u(x,t)\cos\left(\frac{k\pi}{L}x\right)\right]_{x=0}^{x=L}+\frac{k\pi}{L}\int_0^Lu(x,t)\sen\left(\frac{k\pi}{L}x\right)\, dx\right) \\
    &= -\frac{2k^2\pi^2}{L^3} \int_0^Lu(x,t)\sen\left(\frac{k\pi}{L}x\right)\, dx \\
    &= -\frac{k^2\pi^2}{L^2}b_k(t),
\end{align*}
utilizándose en la quinta igualdad que $u(L,t)=u(0,t)=0$. Se tiene entonces
\[b_k'(t) -\frac{k^2\pi^2}{L^2}b_k(t)-B_k(t) = 0,\]
y como $u(x,0) = 0$, entonces $b_k(0) = 0$.

En resumen, si $u$ es solución de $\textup{(PM2)}$, entonces los coeficientes de Fourier de la serie de senos de $u(\cdot,t)$ son solución del problema de ecuaciones diferenciales ordinarias siguiente:
\[\left\{\begin{alignedat}{1}
    b_k'(t)-\frac{k^2\pi^2}{L^2}b_k(t) &= B_k(t), \\
    b_k(0) = 0.
\end{alignedat}\right.\]
Este problema es fácil de resolver, obteniéndose que
\[b_k(t) = \int_0^t B_k(\tau)e^{-\frac{k^2\pi^2}{L^2}(t-\tau)}\, d\tau.\]
En consecuencia,
\[u(\cdot,t) \sim \sum_{k=1}^\infty \left(\int_0^t B_k(\tau)e^{-\frac{k^2\pi^2}{L^2}(t-\tau)}\, d\tau\right)\sen\left(\frac{k\pi}{L}\, \cdot \,\right),\]
obteniéndose una clara candidata a solución del problema...

\begin{theorem}
    Sea $F \in L^2([0,L] \times [0,T])$ y para cada $t \in [0,T]$, sea $B_k(t) = B_k(F(\cdot,t))$.  Entonces la serie
    \[\sum_{k=1}^\infty \left(\int_0^t B_k(\tau)e^{-\frac{k^2\pi^2}{L^2}(t-\tau)}\, d\tau\right)\sen\left(\frac{k\pi}{L}x\right)\]
    converge uniformemente en $[0,L] \times [0,T]$, y la función $u \colon [0,L] \times [0,T] \to \R$ dada por
    \[u(x,t) =\sum_{k=1}^\infty \left(\int_0^t B_k(\tau)e^{-\frac{k^2\pi^2}{L^2}(t-\tau)}\, d\tau\right)\sen\left(\frac{k\pi}{L}x\right) \]
    verifica
    \[u(x,0) = 0, \qquad u(0,t)=0, \qquad u(L,t)=0,\]
    para todo $x\in [0,L]$ y todo $t \in [0,T]$.
\end{theorem}

\begin{proof}
    Evidentemente, se trata de aplicar el criterio de Weierstrass. Para todo $(x,t) \in [0,L] \times [0,T]$, usando que $\alpha\beta\leq\frac{1}{2}(\alpha^2+\beta^2)$ para $\alpha,\beta \in \R$ cualesquiera,
    \begin{align*}
        \left| \left(\int_0^t B_k(\tau)e^{-\frac{k^2\pi^2}{L^2}(t-\tau)}\, d\tau\right)\sen\left(\frac{k\pi}{L}x\right)\right| &\leq \int_0^t |B_k(\tau)e^{-\frac{k^2\pi^2}{L^2}(t-\tau)}|\, d\tau \\
        &\leq \frac{1}{2}\left(\int_0^t B_k(\tau)^2\, d\tau + \int_0^t e^{-\frac{2k^2\pi^2}{L^2}(t-\tau)}\, d\tau\right) \\
        &\leq \frac{1}{2}\left(\int_0^T B_k(\tau)^2\, d\tau + \left[\frac{L^2}{2k^2\pi^2}e^{-\frac{2k^2\pi^2}{L^2}(t-\tau)}\right]_{\tau=0}^{\tau=t}\right) \\
        &\leq \frac{1}{2}\left(\int_0^T B_k(\tau)^2\, d\tau + \frac{L^2}{2k^2\pi^2}\right). \\
    \end{align*}
    Como $\sum_{k=1}^\infty \frac{L^2}{2k^2\pi^2} < \infty$, basta ver que
    \[\sum_{k=1}^\infty \int_0^TB_k(\tau)^2\, d\tau<\infty,\]
    o lo que es lo mismo, por el teorema de la convergencia monótona, que 
    \[\int_0^T\left(\sum_{k=1}^\infty B_k(\tau)^2\right) \, d\tau<\infty.\]
    Por la \hyperref[cor:A.2.10]{\color{gray}igualdad de Parseval}, para cada $\tau \in [0,T]$ se tiene
    \[||F(\cdot,\tau)||_2^2= \sum_{k=1}^\infty B_k(\tau)||\psi_k||_2^2.\]
    Es fácil ver que para todo $k \in \N$,
    \[||\psi_k||_2^2 = \int_0^L \sen^2\left(\frac{k\pi}{L}x\right) \, dx = \frac{L}{2}.\]
    Por tanto,
    \[\int_0^T\left(\sum_{k=1}^\infty B_k(\tau)^2\right) \, d\tau = \int_0^T\frac{2}{L}\, \left(\int_0^L F(x,\tau)^2\, dx\right)d\tau = \frac{2}{L}\int_{[0,L] \times [0,T]}F(x,\tau)\,dx\, d\tau < \infty,\]
    utilizándose el teorema de Fubini y que $F \in L^2([0,T] \times [0,L])$. Del criterio de Weierstrass se obtiene que la serie
    \[\sum_{k=1}^\infty \left(\int_0^t B_k(\tau)e^{-\frac{k^2\pi^2}{L^2}(t-\tau)}\, d\tau\right)\sen\left(\frac{k\pi}{L}x\right)\]
    converge uniformemente en $[0,L] \times [0,T]$. Lo que resta de demostración es inmediato.
\end{proof}

Faltaría probar (no va a hacerse) que bajo ciertas condiciones más fuertes que las del teorema anterior, la función $u$ definida en dicho teorema también satisface la ecuación del calor.

\section{Problemas iniciales asociados a la ecuación del calor}

El problema asociado a la ecuación del calor que se plantea en esta sección es el de hallar $u \in \mathcal{C}^{2,1}(\R \times (0,\infty)) \cap \mathcal{C}(\R \times [0,\infty))$ tal que
\[
    \left\{\begin{alignedat}{5}
        u_{t}(x,t)-u_{xx}(x,t) &= 0, \qquad & x &\in \R, \ & t &>0, \\
        u(x,0) &= u_0(x), \qquad & x &\in \R. & & \\
    \end{alignedat}\right.
\]
Puede probarse que si se cambia $[0,\infty)$ por $[0,T]$ para cualquier $T \in (0,\infty)$, el problema tiene, a lo sumo, una solución acotada. Para hallar la solución, va a ser de gran utilidad lo estudiado en el \hyperref[B]{\color{gray}Apéndice B}.

Supongamos que $u \colon \R \times [0,\infty) \to \R$ es una solución del problema lo suficientemente regular. Para cada $\xi \in \R$ y cada $t > 0$, sea
\[\widehat{u}(\xi,t) = \frac{1}{\sqrt{2\pi}}\int_\R u(x,t)e^{-i\xi x} \, dx,\]
es decir, se está denotando por $\widehat{u}(\xi,t)$ a la transformada de Fourier de la función $u(\cdot, t)$ evaluada en $\xi$. Por abreviar la notación, se va a hacer lo mismo para $u_t$ y $u_{xx}$. Así, por la \hyperref[pro:B.1.2]{\color{gray}Proposición B.1.2},
\[\widehat{u_{xx}}(\xi,t) = (i\xi)^2\widehat{u}(\xi,t) = -\xi^2 \widehat{u}(\xi,t).\]
Por otra parte,
\[\widehat{u_t}(\xi,t)= \frac{1}{\sqrt{2\pi}}\int_\R u_t(x,t) e^{-i\xi x} \, dx = \widehat{u}_t(\xi,t),\]
donde la primera igualdad se tiene por definición y la segunda por el teorema de derivación bajo el signo integral. Como
\[u_t(\xi,t)-u_{xx}(\xi,t)=0,\]
entonces, usando la linealidad de la transformada de Fourier,
\[\widehat{u_t}(\xi,t) -\widehat{u_{xx}}(\xi,t) = 0,\]
es decir,
\[\widehat{u}_t(\xi,t) +\xi^2\widehat{u}(\xi,t) = 0.\]
Y como $u(\xi,0) = u_0(\xi)$, también debe verificarse $\widehat{u}(\xi,0) = \widehat{u_0}(\xi)$. Se tiene entonces que para cada $\xi \in \R$, $\widehat{u}(\xi,\cdot)$ es solución del problema de Cauchy
\[\left\{\begin{alignedat}{2}
    \widehat{u}_t(\xi,t) &= -\xi^2 \widehat{u}(\xi,t), \qquad t > 0, \\
    \widehat{u}(\xi,0) &= \widehat{u_0}(\xi).
\end{alignedat}\right.\]
Este problema es fácil de resolver: \[\widehat{u}(\xi,t) = \widehat{u_0}(\xi)e^{-\xi^2t}. \tag{$\ast$}\]
Por el \hyperref[teo:B.4.1]{\color{gray}teorema de inversión},
\[u(x,t) =\frac{1}{\sqrt{2\pi}} \int_\R \widehat{u_0}(\xi)e^{-\xi^2t}e^{i\xi x} \, d\xi,\]
lo que proporciona, en términos informales, una candidata a solución del problema. 

El \hyperref[eje:B.3.2]{\color{gray}Ejemplo B.3.2} sugiere escribir $u$ de otra manera: si para cada $\alpha \in \R$ llamamos $k_\alpha(x)=e^{-\alpha x^2}$, entonces $k_\alpha \in L^1(\R)$ y
\[\widehat{k_\alpha}(\xi )  = \frac{1}{\sqrt{2\alpha}}k_{\frac{1}{4\alpha}}(\xi) = \frac{1}{\sqrt{2\alpha}}e^{-\frac{x^2}{4\alpha}}\]
para todo $\xi \in \R$, de donde se deduce que
\[e^{-\xi^2t} = \frac{1}{\sqrt{2t}}\widehat{k_{\frac{1}{4t}}}(\xi)\]
para todo $\xi \in \R$ y todo $t > 0$. En consecuencia, ($\ast$) se convierte en
\[\widehat{u}(\xi,t) = \frac{1}{\sqrt{2t}}\widehat{u_0}(\xi)\widehat{k_{\frac{1}{4t}}}(\xi).\]
Por tanto, por la \hyperref[pro:B.2.2]{\color{gray}Proposición B.2.2},
\[\widehat{u}(\xi,t) = \frac{1}{\sqrt{2t}}\frac{1}{\sqrt{2\pi}}\widehat{u_0 \ast k_{\frac{1}{4t}}}(\xi) =  \frac{1}{2\sqrt{\pi t}}\widehat{u_0 \ast k_{\frac{1}{4t}}}(\xi),\]
y por el \hyperref[cor:B.4.2]{\color{gray}Corolario B.4.2},
\[u(x,t) = \frac{1}{2\sqrt{\pi t}}u_0 \ast k_{\frac{1}{4t}}(x) = \frac{1}{2\sqrt{\pi t}} \int_\R u_0(y)e^{-\frac{(x-y)^2}{4t}} \, dx.\]
Nótese que la igualdad se da en todo $x \in \R$ (no solo en casi todo $x \in \R$, que es lo que dice el corolario) porque $u$ y $u_0 \ast k_{\frac{1}{4t}}$ son continuas.

\begin{definition}
    A la función $K \colon \R \times (0,\infty) \to \R$ dada por
    \[K(x,t) = \frac{1}{2\sqrt{\pi t}}e^{-\frac{x^2}{4t}}\]
    se le conoce como \emph{solución fundamental de la ecuación del calor}, \emph{núcleo de Gauss} o \emph{núcleo del calor}.
\end{definition}

Es fácil probar que la solución fundamental de la ecuación del calor es, como cabe sospechar, una solución de la ecuación del calor.

\begin{theorem}
    Sea $u_0 \colon \R \to \R$ continua y acotada, y sea $u \colon \R \times [0,\infty) \to \R$ la función dada por
    \[u(x,t) = \begin{cases}
        \displaystyle \frac{1}{2\sqrt{\pi t}} \int_\R u_0(y)e^{-\frac{(x-y)^2}{4t}} \, dy & $ si $ t < 0, \\[10pt]
        u_0(x) & $ si $ t = 0.
    \end{cases}\] 
    Entonces $u$ es acotada, está en $\mathcal{C}^\infty(\R \times (0,\infty)) \cap \mathcal{C}(\R \times [0,\infty))$ y verifica 
    \[u_t(x,t)-u_{xx}(x,t) = 0\]
    para todo $(x,t) \in \R \times (0,\infty)$.
    En consecuencia, para cada $T > 0$, $u$ es la única solución acotada del problema
\[
    \left\{\begin{alignedat}{5}
        u_{t}(x,t)-u_{xx}(x,t) &= 0, \qquad & x &\in \R, \ & t &\in (0,T), \\
        u(x,0) &= u_0(x), \qquad & x &\in \R. & & \\
    \end{alignedat}\right.
\]
\end{theorem}

\chapter{Ecuación de Laplace}

\begin{definition}
    Sea $\Omega \subset \R^n$ un abierto y sea $f \in \mathcal{C}(\Omega)$. La \emph{ecuación de Poisson} es
    \[\Delta u(x) = f(x), \qquad x \in \Omega.\]
    Si $F = 0$, se habla de \emph{ecuación de Laplace}.
\end{definition}

En este tema se dará especial importancia a la ecuación de Laplace; de la de Poisson pasaremos olímpicamente. 

Por otro lado, los problemas asociados a la ecuación de Laplace que van a estudiarse son los siguientes:

\begin{definition}
    Sea $\Omega \subset \R^n$ un dominio acotado y sea $\varphi \in \mathcal{C}(\partial \Omega)$. Se llama \emph{problema de Dirichlet asociado a la ecuación de Laplace} al problema de determinar $u \in \mathcal{C}^2(\Omega) \cap \mathcal{C}(\overline{\Omega})$ tal que
    \[\left\{\begin{alignedat}{3}
        \Delta u(x) &= 0, \qquad & x &\in \Omega, \\
        u(x) &= \varphi(x), \qquad & x &\in \partial \Omega.
    \end{alignedat}\right.\]
\end{definition}

Antes de resolver este problema en algunos casos concretos se va estudiar la unicidad de soluciones, que, como en el tema anterior, es consecuencia del siguiente principio del máximo:

\begin{theorem}[Principio del máximo débil]
    Sea $\Omega \subset \R^n$ un dominio acotado y sea $u \in \mathcal{C}^2(\Omega) \cap \mathcal{C}(\overline{\Omega})$ tal que $\Delta u(x) \geq 0$ para todo $x \in \Omega$. Entonces
    \[\max_{x \in \overline{\Omega}} u(x) = \max_{x \in \partial \Omega} u(x).\]
\end{theorem}

\begin{proof}
    Supóngase primero que $\Delta u(x) > 0$ para todo $x \in \Omega$. Si existiese $x_0 \in \Omega$ tal que
    \[u(x_0) = \max_{x \in \overline{\Omega}}u(x),\]
    entonces, por ser la matriz hessiana de $u$ en $x_0$ semidefinida negativa, se tendría que $\Delta u(x) \leq 0$, que contradice lo supuesto. Por tanto,
    \[\max_{x \in \overline{\Omega}} u(x) = \max_{x \in \partial\Omega} u(x).\]

    Supóngase ahora que $\Delta u(x) \geq 0$ para todo $x \in \Omega$. Sea $K >0$ y sea $v \colon \overline{\Omega} \to \R$ la función dada por
    \[v(x) = u(x) + K||x||^2 = u(x) + K(x_1^2+\mathellipsis+x_n^2).\]
    Es claro que $v \in \mathcal{C}^2(\Omega) \cap \mathcal{C}(\overline{\Omega})$, y además, para todo $x \in \Omega$,
    \[\Delta v(x) = \underbracket{\Delta u(x)}_{\geq 0} + \underbracket{2nK}_{>0} >0.\]
    Por lo probado anteriormente, se tiene que
    \[\max_{x \in \overline{\Omega}} v(x) = \max_{x \in \partial \Omega} v(x).\]
    Por otra parte, como $\overline{\Omega}$ es acotado, existe $R>0$ tal que $||x|| \leq R$ para todo $x \in \Omega$. Como consecuencia de todo esto,
    \[\max_{x \in \overline{\Omega}} u(x) \leq \max_{x \in \overline{\Omega}} v(x) = \max_{x \in \partial \Omega} v(x) \leq \max_{x \in \partial \Omega} u(x) + KR^2, \tag{$\ast$}\]
    utilizándose en la primera desigualdad que $u(x) \leq v(x)$ para todo $x \in \overline{\Omega}$, y en la segunda desigualdad que $v(y) \leq \max_{x \in \partial \Omega} u(x)+KR^2$ para todo $y \in \partial\Omega$. Como $(\ast)$ es cierto para todo $K > 0$, tomando límites cuando $K \to 0^+$ se obtiene
    \[\max_{x \in \overline{\Omega}}u(x) \leq \max_{x \in \partial\Omega} u(x).\]
    Y como $\partial\Omega \subset \overline{\Omega}$, la otra desigualdad es trivial.
\end{proof}


\begin{corollary}[Principio del mínimo débil]
    Sea $\Omega \subset \R^n$ un dominio acotado y sea $u \in \mathcal{C}^2(\Omega) \cap \mathcal{C}(\overline{\Omega})$ tal que $\Delta u(x) \leq 0$ para todo $x \in \Omega$. Entonces
    \[\min_{x \in \overline{\Omega}} u(x) = \min_{x \in \partial \Omega} u(x).\]
\end{corollary}

\begin{proof}
    Aplíquese el resultado anterior a $-u$.
\end{proof}

\begin{corollary}
    Sea $\Omega \subset \R^n$ un dominio acotado y sea $u \in \mathcal{C}^2(\Omega) \cap \mathcal{C}(\overline{\Omega})$ tal que $\Delta u(x) = 0$ para todo $x \in \Omega$. Entonces
    \[\max_{x \in \overline{\Omega}} |u(x)| = \max_{x \in \partial \Omega} |u(x)|.\]
\end{corollary}

\begin{proof}
    Aplíquense los dos resultados anteriores teniendo en cuenta que para cualquier subconjunto $D \subset \R^n$ y cualquier función $f \colon D \to \R$ que alcance el máximo y el mínimo, se verifica
    \[\max_{x \in D} |f(x)| = \max\left\{\max_{x \in D}f(x),-\min_{x \in D}f(x)\right\}. \qedhere\]
\end{proof}

\begin{theorem}
    El problema de Dirichlet asociado a la ecuación de Laplace tiene, a lo sumo, una solución.
\end{theorem}

\begin{proof}
    Sea $\Omega \subset \R^n$ un dominio acotado y sean $u$ y $v$ soluciones de dicho problema en $\Omega$. Sea $w = u-v$. Entonces $w \in \mathcal{C}^2(\Omega) \cap \mathcal{C}(\overline{\Omega})$ y $\Delta w(x) = 0$ para todo $x \in \Omega$, luego, por el corolario anterior,
    \[\max_{x \in \overline{\Omega}} |w(x)| = \max_{x \in \partial \Omega} |w(x)|.\]
    Ahora basta tener en cuenta que $w(x,y) = 0$ para todo $(x,y) \in \partial \Omega$, obteniéndose que $w = 0$ y, por tanto, que $u = v$.
\end{proof}

Nótese que la demostración del teorema anterior también es válida para el problema de Dirichlet asociado a la ecuación de Poisson.


\section{Problema de Dirichlet en un rectángulo}

En esta sección se va a resolver el problema anterior considerando el dominio acotado $(0,1) \times (0,1)$ de $\R^2$. Así, se trata de hallar $u \in \mathcal{C}^2((0,1) \times (0,1)) \cap \mathcal{C}([0,1] \times [0,1])$ tal que
\[\left\{\begin{alignedat}{5}
    \Delta u(x,y) &= 0, \qquad & x &\in (0,1), \ & y &\in (0,1), \\
    u(x,0) &= \varphi_1(x), \qquad & x &\in [0,1], & & \\
    u(x,1) &= \varphi_2(x), \qquad & x &\in [0,1], & & \\
    u(0,y) &= \varphi_3(y), \qquad & & & y &\in [0,1], \\
    u(1,y) &= \varphi_4(y), \qquad & & & y &\in [0,1], \\
\end{alignedat}\right.\]
donde $\varphi_1,\varphi_2,\varphi_3,\varphi_4 \in \mathcal{C}([0,1])$. Por la linealidad de la ecuación, no se pierde generalidad si nos limitamos a resolver los problemas
\[\left\{\begin{alignedat}{5}
    \Delta u(x,y) &= 0, \qquad & x &\in (0,1), \ & y &\in (0,1), \\
    u(x,0) &= \varphi_1(x), \qquad & x &\in [0,1], & & \\
    u(x,1) &= 0, \qquad & x &\in [0,1], & & \\
    u(0,y) &= 0, \qquad & & & y &\in [0,1], \\
    u(1,y) &= 0, \qquad & & & y &\in [0,1], \\
\end{alignedat}\right. \qquad \left\{\begin{alignedat}{5}
    \Delta u(x,y) &= 0, \qquad & x &\in (0,1), \ & y &\in (0,1), \\
    u(x,0) &= 0, \qquad & x &\in [0,1], & & \\
    u(x,1) &= \varphi_2(x), \qquad & x &\in [0,1], & & \\
    u(0,y) &= 0, \qquad & & & y &\in [0,1], \\
    u(1,y) &= 0, \qquad & & & y &\in [0,1], \\
\end{alignedat}\right.\]
\[\left\{\begin{alignedat}{5}
    \Delta u(x,y) &= 0, \qquad & x &\in (0,1), \ & y &\in (0,1), \\
    u(x,0) &= 0, \qquad & x &\in [0,1], & & \\
    u(x,1) &= 0, \qquad & x &\in [0,1], & & \\
    u(0,y) &= \varphi_3(x), \qquad & & & y &\in [0,1], \\
    u(1,y) &= 0, \qquad & & & y &\in [0,1], \\
\end{alignedat}\right. \qquad \left\{\begin{alignedat}{5}
    \Delta u(x,y) &= 0, \qquad & x &\in (0,1), \ & y &\in (0,1), \\
    u(x,0) &= 0, \qquad & x &\in [0,1], & & \\
    u(x,1) &= 0, \qquad & x &\in [0,1], & & \\
    u(0,y) &= 0, \qquad & & & y &\in [0,1], \\
    u(1,y) &= \varphi_4(x), \qquad & & & y &\in [0,1]. \\
\end{alignedat}\right.\]
Evidentemente, solo se va a resolver uno de ellos (los demás son análogos), por ejemplo el primero:
\[\textup{(PD1)} \ \left\{\begin{alignedat}{5}
    \Delta u(x,y) &= 0, \qquad & x &\in (0,1), \ & y &\in (0,1), \\
    u(x,0) &= \varphi_1(x), \qquad & x &\in [0,1], & & \\
    u(x,1) &= 0, \qquad & x &\in [0,1], & & \\
    u(0,y) &= 0, \qquad & & & y &\in [0,1], \\
    u(1,y) &= 0, \qquad & & & y &\in [0,1]. \\
\end{alignedat}\right.\]
Como se costumbre, se va a suponer que $w \colon (0,1) \times (0,1) \to \R$ es una solución no nula del problema de la forma $w(x,y)=v(x)u(y)$, y se van a tratar de hallar $u$ y $v$. Razonando como en otras ocasiones, se prueba que para algún $\lambda  \in \R$, $v$ debe resolver el problema
\[
\left\{\begin{alignedat}{1}
    v''(x)-\lambda v(x) &= 0, \qquad x \in (0,1), \\
    v(0) &= 0, \\
    v(1) &= 0,
\end{alignedat}\right.
\]
y $u$ debe resolver el problema
\[\left\{\begin{alignedat}{1}
    u''(y)+\lambda u(y) &= 0, \qquad y \in (0,1), \\
    u(1) &= 0.
\end{alignedat}\right.\]
Respecto al primer problema, ya se ha visto anteriormente que existen soluciones no nulas si y solo si $\lambda = -k^2\pi^2$ para cualquier $k \in \N$, en cuyo caso las soluciones son
\[v_k(x) = A\sen(k\pi x), \qquad x\in(0,1),\]
para cualquier constante $A \in \R$. Ahora habría que resolver el problema
\[\left\{\begin{alignedat}{1}
    u''(y)-k^2\pi^2 u(y) &= 0, \qquad y \in (0,1), \\
    u(1) &= 0.
\end{alignedat}\right.\]
Es fácil ver que
\[u_k(y)= Be^{k\pi y}-Be^{2k\pi}e^{-k\pi y}, \qquad y \in (0,1),\]
para cualquier constante $B \in \R$. Es decir,
\[u_k(y)= \beta \senh(k\pi(y-1)), \qquad y \in (0,1),\]
para cualquier constante $\beta \in \R$. Por tanto, omitiendo las constantes,
\[w_k(x,y)=\sen(k\pi x)\senh(k\pi(y-1)), \qquad x \in (0,1), \ y \in (0,1).\]
Ahora cabe preguntarse si existe una sucesión $\{\alpha_k\}_{k=1}^\infty$ de números reales tal que la función $u \colon [0,1] \times [0,1] \to \R$ dada por
\[u(x,y) = \sum_{k=1}^\infty \alpha_k\sen(k\pi x)\senh(k\pi(y-1))\]
esté bien definida y resuelva el problema. Como debe tenerse $u(x,0) = \varphi_1(x)$, habría que tomar $\alpha_k$ tal que
\[\alpha_k\senh(-k\pi) = b_k(\varphi),\]
o sea,
\[\alpha_k= \frac{b_k(\varphi)}{\senh(-k\pi)} = -\frac{b_k(\varphi)}{\senh(k\pi)},\]
donde $b_k(\varphi) = 2\int_0^1 \varphi(x) \sen(k\pi x) \, dx$. En consecuencia, la candidata a solución sería la función $u \colon [0,1] \times [0,1] \to \R$ dada por
\[u(x,y) = \sum_{k=1}^\infty -\frac{b_k(\varphi)\senh(k\pi(y-1))}{\senh(k\pi)}\sen(k\pi x) = \sum_{k=1}^\infty \frac{b_k(\varphi)\senh(k\pi(1-y))}{\senh(k\pi)}\sen(k\pi x). \]

\begin{theorem}
    Sea $\varphi \colon [0,1] \to \R$ continua, de clase $1$ a trozos y tal que $\varphi(0)=\varphi(1)=0$. Entonces la serie 
    \[ \sum_{k=1}^\infty \frac{b_k(\varphi)\senh(k\pi(1-y))}{\senh(k\pi)}\sen(k\pi x)\]
    converge uniformemente en $[0,1] \times [0,1]$, y la función $u \colon [0,1] \times [0,1] \to \R$ dada por
    \[u(x,t) =  \sum_{k=1}^\infty \frac{b_k(\varphi)\senh(k\pi(1-y))}{\senh(k\pi)}\sen(k\pi x)\]
    está en $\mathcal{C}^2((0,1) \times (0,1)) \cap \mathcal{C}([0,1] \times [0,1])$ y es solución de $\textup{(PD1)}$. 
\end{theorem}

\section{Problema de Dirichlet en un disco}

Ahora se va a tratar de encontrar la solución del problema de Dirichlet en un disco de $\R^2$, es decir, en el dominio acotado $B(0,R) = \{(x,y) \in \R^2 \colon x^2+y^2 < 1 \}$, para cualquier $R >0$. Dada $\varphi \in \mathcal{C}(\partial B(0,R))$, hay que hallar $u \in \mathcal{C}^2(B(0,R)) \cap \mathcal{C}(\overline{B}(0,R))$ tal que
\[\left\{\begin{alignedat}{3}
    \Delta u(x,y) &= 0, \qquad & (x,y) &\in B(0,R), \\
    u(x,y) &= \varphi(x,y), \qquad & (x,y) &\in \partial B(0,R).
\end{alignedat}\right.\]
Para lograr esta misión es conveniente expresar el problema anterior en coordenadas polares. Resulta ligeramente fatigoso probar que este problema es equivalente al problema de determinar $v \in \mathcal{C}^2((0,R) \times [-\pi,\pi]) \cap \mathcal{C}([0,R] \times [-\pi,\pi])$ tal que
\[\left\{\begin{alignedat}{5}
    v_{\rho\rho}(\rho,\theta)+\frac{1}{\rho^2}v_{\theta\theta}(\rho,\theta)+\frac{1}{\rho}v_\rho(\rho,\theta) &= 0, \qquad & \rho &\in (0,R), \ &\theta &\in (-\pi,\pi), \\
    v(R,\theta) &= g(\theta), \qquad & & & \theta &\in (-\pi,\pi),
\end{alignedat}\right.\]
donde $g(\theta) = \varphi(R\cos\theta,R\sen\theta)$, y tal que
\[\left\{\begin{alignedat}{6}
    v(\rho,-\pi) &= v(\rho,\pi), & & \qquad & \rho &\in (0,R),  \\
    v_\theta(\rho,-\pi) &= v_\theta(\rho,\pi), & \ v_\rho(\rho,-\pi) &= v_\rho(\rho,\pi), \qquad & \rho &\in (0,R), \\
    v_{\theta\theta}(\rho,-\pi) &= v_{\theta\theta}(\rho,\pi), & \ v_{\rho\rho}(\rho,-\pi) &= v_{\rho\rho}(\rho,\pi), \ v_{\rho\theta}(\rho,-\pi) = v_{\rho\theta}(\rho,\pi), \qquad & \rho &\in (0,R).\\
\end{alignedat}\right.\]
Nótese que la condición $v_{\theta\rho}(\rho,-\pi) = v_{\theta\rho}(\rho,\pi)$ es reduntante porque $v$ es de clase $2$.

Se trata ahora se hallar soluciones $w \colon [0,R] \times [-\pi,\pi] \to \R$ de este arduo problema que sean no nulas y que tomen la forma $w(\rho,\theta)=\Phi(\rho)S(\theta)$. Debe verificarse entonces
\[\Phi(\rho)S''(\theta)+\rho \Phi'(\rho)S(\theta)+\rho^2\Phi''(\rho)S(\theta) = 0, \qquad \rho \in (0,R), \ \theta \in (-\pi,\pi),\]
de donde se deduce que debe tenerse
\[S''(\theta)+\lambda S(\theta)=0, \qquad \theta \in (-\pi,\pi),\]
y también
\[\rho^2\Phi''(\rho)+\rho \Phi'(\rho)-\lambda \Phi(\rho) = 0, \qquad \rho \in (0,R),\]
para algún $\lambda \in \R$.
Las condiciones $w(\rho,-\pi) = w(\rho,\pi)$ y $w_\theta(\rho,-\pi) = w_\theta(\rho,\pi)$ se traducen en $S(-\pi)=S(\pi)$ y $S'(-\pi) = S'(\pi)$, y es fácil ver que esto implica el resto de condiciones que deben tenerse sobre $w$ y sus derivadas en $(\rho,\pi)$ y $(\rho,-\pi)$. Por tanto, $S$ debe resolver el problema
\[\left\{\begin{alignedat}{2}
    S''(\theta)+\lambda S(\theta) &= 0, \qquad \theta \in (-\pi,\pi), \\
    S(-\pi) &= S(\pi), \\
    S'(-\pi) &= S'(\pi).
\end{alignedat}\right.\]
Haciendo un par de cuentas sencillas se prueba que el problema anterior tiene soluciones no nulas si y solo si $\lambda = k^2$ para algún $k \in \N \cup \{0\}$, y dichas soluciones son
\[S_k(\theta) = A_k\cos(k\theta)+B_k\sen(k \theta), \qquad \theta \in (-\pi,\pi),\]
con $A_k,B_k \in \R$ constantes cualesquiera. Ahora se resuelve la ecuación para $\Phi$ con $\lambda = k^2$, $k \in \N \cup \{0\}$. Si $k = 0$, la ecuación a resolver es
\[\rho^2\Phi''(\rho)+\rho \Phi'(\rho) = 0, \qquad \rho \in (0,R),\]
y su solución,
\[\Phi_0(\rho) = C_0+D_0\log(\rho), \qquad \rho \in (0,R),\]
con $C_0,D_0 \in \R$ constantes cualesquiera. Para $k > 0$, la ecuación a resolver es una ecuación de Euler, que se resuelve buscando soluciones de la forma $\Phi(\rho) = \rho^\alpha$. Se tiene que
\begin{align*}
    \rho^2\Phi''(\rho) +\rho \Phi'(\rho) -k^2\Phi(\rho) = 0 &\iff \alpha(\alpha-1)\rho^2\rho^{\alpha-2}+\alpha\rho\rho^{\alpha-1}-k^2\rho^\alpha = 0 \\
    &\iff \alpha(\alpha-1)\rho^{\alpha}+\alpha\rho^{\alpha}-k^2\rho^\alpha = 0. \\
    &\iff \alpha^2\rho^\alpha-k^2\rho^\alpha = 0.
\end{align*}
Por tanto, debe ser $\alpha = \pm k$. De todo esto se deduce que las soluciones de la ecuación para $\Phi$ con $\lambda = k^2$, donde $k \in \N$, son
\[\Phi_k(\rho) = C_k\rho^{k}+D_k \rho^{-k}, \qquad \rho \in (0,R),\]
con $C_k,D_k \in \R$ constantes cualesquiera. Como $\Phi_k$ debe ser continua en $[0,R]$, para que tenga límite en $0$ hay que tomar $D_k = 0$ (esto también atañe al caso $k = 0$). Y, para simplificar las cosas, se tomará $C_k = 1$ para cada $k \in \N \cup \{0\}$. Así,
\[w_k(\rho,\theta) = A_k\rho^k\cos(k\theta)+B_k\rho^k\sen(k\theta), \qquad \rho \in (0,R), \ \theta \in (-\pi,\pi).\]
Como siempre, ahora hay que preguntarse si la función $v \colon [0,R] \times [-\pi,\pi] \to \R$ dada por
\[v(\rho,\theta) = \sum_{k=0}^\infty \left(A_k\rho^k \cos(k\theta)+B_k\rho^k\sen(k\theta)\right),\]
es solución del problema de Dirichlet en coordenadas polares. También como siempre, la respuesta a esta pregunta se va a enunciar sin demostrarse. Antes de ello, nótese que para que se verifique $v(R,\theta) = g(\theta)$ debe tenerse que $A_kR^k = a_k(g)$ y $B_kR^k = b_k(g)$ para todo $k \in \N$, mientras que $A_0 = \frac{a_0(g)}{2}$, donde
\[a_k(g) = \frac{1}{\pi}\int_{-\pi}^\pi g(\theta) \cos(k\theta) \, d\theta\]
para cada $k \in\N \cup \{0\}$, y
\[b_k(g) = \frac{1}{\pi}\int_{-\pi}^\pi g(\theta) \sen(k\theta) \, d\theta\]
para cada $k \in \N$.

\begin{theorem}
    Sea $g \colon [-\pi,\pi] \to \R$ continua, de clase $1$ a trozos y tal que $g(-\pi)=g(\pi)$. Entonces la serie
    \[\frac{a_0(g)}{2}+ \sum_{k=1}^\infty \left(a_k(g)\left(\frac{\rho}{R}\right)^k \cos(k\theta)+b_k(g)\left(\frac{\rho}{R}\right)^k\sen(k\theta)\right)\]
    converge uniformemente en $\rho \in [0,R] \times [-\pi,\pi]$, y la función $v \colon [0,R] \times [-\pi,\pi] \to \R$ dada por
    \[v(\rho,\theta) = \frac{a_0(g)}{2}+ \sum_{k=1}^\infty \left(a_k(g)\left(\frac{\rho}{R}\right)^k \cos(k\theta)+b_k(g)\left(\frac{\rho}{R}\right)^k\sen(k\theta)\right)\]
    está en $\mathcal{C}^2((0,R) \times [-\pi,\pi]) \cap \mathcal{C}([0,R] \times [-\pi,\pi])$ y verifica
    \begin{itemize}
        \item $\displaystyle\left\{\begin{alignedat}{5}
    v_{\rho\rho}(\rho,\theta)+\frac{1}{\rho^2}v_{\theta\theta}(\rho,\theta)+\frac{1}{\rho}v_\rho(\rho,\theta) &= 0, \qquad & \rho &\in (0,R), \ &\theta &\in (-\pi,\pi), \\
    v(R,\theta) &= g(\theta), \qquad & & & \theta &\in (-\pi,\pi).
    \end{alignedat}\right.$
    \item $\displaystyle \left\{\begin{alignedat}{6}
        v(\rho,-\pi) &= v(\rho,\pi), & & \qquad & \rho &\in (0,R),  \\
        v_\theta(\rho,-\pi) &= v_\theta(\rho,\pi), & \ v_\rho(\rho,-\pi) &= v_\rho(\rho,\pi), \qquad & \rho &\in (0,R), \\
        v_{\theta\theta}(\rho,-\pi) &= v_{\theta\theta}(\rho,\pi), & \ v_{\rho\rho}(\rho,-\pi) &= v_{\rho\rho}(\rho,\pi), \ v_{\rho\theta}(\rho,-\pi) = v_{\rho\theta}(\rho,\pi), \qquad & \rho &\in (0,R).\\
    \end{alignedat}\right.$
    \end{itemize}
\end{theorem}

\section{Funciones armónicas}

Las funciones que resuelven la ecuación de Laplace tienen el suficiente interés como para que se les dedique una definición. En esta sección se enuncian sin demostrarse algunas propiedades interesantes de este tipo de funciones. 

\begin{definition}
    Sea $\Omega$ un abierto de $\R^n$ y sea $u \in \mathcal{C}^2(\Omega,\R)$. Se dice que $u$ es \emph{armónica en $\Omega$}, o simplemente \emph{armónica}, si $\Delta u(x) = 0$ para todo $x \in \Omega$. 
\end{definition}

\begin{theorem}
    Si $\Omega$ es un abierto de $\R^n$ y $u \colon \Omega \to \R$ es armónica, entonces $u \in \mathcal{C}^\infty(\Omega)$.
\end{theorem}

\begin{theorem}[Propiedad de la media]
    Sea $\Omega$ un abierto de $\R^n$ y sea $u \colon \Omega \to \R$ una función armónica. Si $x_0 \in \R^n$ y $r > 0$ son tales que $\overline{B(x_0,r)} \subset \Omega$, entonces
    \[u(x_0) = \frac{1}{\pi r^2} \int_{B(x_0,r)} u(x) \, dx, \qquad \qquad u(x_0) = \frac{1}{2\pi r} \int_{C(x_0,r)} u(P) \, ds(P).\]
\end{theorem}

En otras palabras, el resultado anterior dice que $u(x_0)$ coincide con la media de los valores de $u$ en el disco $B(x_0,r)$ o en la circunferencia $C(x_0,r)$.

\begin{theorem}[Principio del máximo fuerte]
    Sea $\Omega$ un dominio de $\R^n$ y sea $u \in \mathcal{C}^2(\Omega)$ tal que $\Delta u(x) \geq 0$ para todo $x \in \Omega$. Si existe $x_0 \in \Omega$ tal que
    \[u(x_0) = \sup_{x \in \Omega} u(x),\]
    entonces $u$ es constante.
\end{theorem}

\begin{corollary}[Principio del mínimo fuerte]
    Sea $\Omega$ un dominio de $\R^n$ y sea $u \in \mathcal{C}^2(\Omega)$ tal que $\Delta u(x) \leq 0$ para todo $x \in \Omega$. Si existe $x_0 \in \Omega$ tal que
    \[u(x_0) = \inf_{x \in \Omega} u(x),\]
    entonces $u$ es constante.
\end{corollary}

\begin{corollary}
    Sea $\Omega$ un dominio de $\R^n$ y sea $u \colon \Omega \to \R$ armónica en $\Omega$. Si existe $x_0 \in \Omega$ tal que
    \[u(x_0) = \sup_{x \in \Omega} u(x),\]
    entonces $u$ es constante.
\end{corollary}

\appendix

\chapter{Series de Fourier}\label{A}

Al tratar de resolver el problema (PMD) que figura en la \hyperref[def:3.3.1]{\color{gray}Definición 3.3.1} ha aparecido la siguiente cuestión: si $f \colon [0,L] \to \R$, ¿existe una sucesión $\{b_k\}_{k=1}^\infty$ de números reales tal que
\[f(x)=\sum_{k=1}^\infty b_k\sen\left(\frac{k\pi}{L}x\right)\]
para todo $x \in [0,L]$? Y si el problema que se quiere resolver es (PMN), hay que preguntarse lo siguiente: si $f \colon [0,L] \to \R$, ¿existe una sucesión $\{a_k\}_{k=0}^\infty$ de números reales tal que
\[f(x)=A_0+\sum_{k=1}^\infty a_k\cos\left(\frac{k\pi}{L}x\right)\]
para todo $x \in [0,L]$? Estudiémoslo.

\section[Sistemas ortogonales en \texorpdfstring{$L^2$}{L2}]{Sistemas ortogonales en \texorpdfstring{\boldmath$L^2$}{L2}}

A partir de ahora se va a trabajar en espacios de medida $([a,b],\mathcal{L}_{[a,b]},m_{[a,b]})$, donde $\mathcal{L}$ es la $\sigma$-álgebra de Lebesgue y $m$ es la medida de Lebesgue. Como la única medida que se va a manejar es la de Lebesgue, para acortar notación, en lugar de $\int_a^b f \, d\!m$
o de $\int_a^b f(x) \, dx$, se escribirá simplemente $\int_a^b f$.
Y para cada $p \in [1,\infty)$, se denota
\[\mathcal{L}^p([a,b]) = \left\{f \colon [a,b] \to \R \colon f \textup{ es medible y } \int_a^b |f|^p \, < \infty\right\}.\]
En $\mathcal{L}^([a,b])$ se introduce la relación $\sim$ siguiente:
\[f \sim g \iff f = g \textup{ en casi todo punto}.\]
Resulta que esta relación es de equivalencia, y se define
\[L^p([a,b]) = \bigslant{\mathcal{L}^p([a,b])}{\sim}.\]
Aunque los elementos de $L^p([a,b])$ son clases de equivalencia, por comodidad se les denotará como si fuesen funciones. Así, en lugar de $[f] \in L^p([a,b])$ se escribe simplemente $f \in L^p([a,b])$. 

Se resaltan a continuación algunas propiedades elementales de los espacios $L^p([a,b])$, ya estudiadas en la asignatura \emph{Análsis Real}:
\begin{itemize}
    \item $L^p([a,b])$ es un espacio vectorial sobre $\R$. 
    \item La aplicación $||\cdot||_p \colon L^p([a,b]) \to \R$ definida por
    \[||f||_p = \left(\int_a^b |f|^p\right)^\frac{1}{p}\]
    es una norma, y el espacio normado $(L^p([a,b]),||\cdot||_p)$ es completo, o sea, es un espacio de Banach.
    \item Si $p \leq q$, entonces $L^q([a,b]) \subset L^p([a,b])$ (esto sigue siendo cierto en cualquier espacio de medida finita). Sin embargo, $L^q(\R) \not\subset L^p(\R)$ y $L^p(\R) \not\subset L^q(\R)$.
    \item Si $p$ y $p'$ son exponentes conjugados (o sea, $\frac{1}{p}+\frac{1}{p'} = 1$), $f \in L^p([a,b])$ y $g \in L^{p'}([a,b])$, entonces $fg \in L^1([a,b])$ y 
    \[\int_a^b |fg| \leq \left(\int_a^b |f|^p\right)^{\frac{1}{p}}\left(\int_a^b |g|^{p'}\right)^{\frac{1}{p'}},\]
    es decir,
    \[||fg||_1 \leq ||f||_p||g||_{p'}.\]
    Esta desigualdad se conoce popularmente como \emph{desigualdad de Hölder}, y si $p=p'=2$, como \emph{desigualdad de Schwarz}.
    \item El caso $p=2$ es particularmente interesante, pues si se define $\langle\cdot,\cdot\rangle \colon L^2([a,b]) \to \R$ mediante
    \[\langle f,g\rangle = \int_a^b fg\]
    resulta que $(L^2([a,b]),\langle\cdot,\cdot\rangle)$ es un espacio de Hilbert, y la norma asociada a $\langle\cdot,\cdot\rangle$ es precisamente $||\cdot||_2$. Esto le confiere a $L^2([a,b])$ unas propiedades magníficas y muy útiles en relación con esto de las series de Fourier. Como consecuencia de la desigualdad de Schwarz, se tiene que
    \[|\langle f,g\rangle| \leq ||f||_2||g||_2\]
    para $f,g \in L^2([a,b])$ cualesquiera.
\end{itemize}

\begin{definition}
    Sean $f,g \in L^2([a,b])$. Se dice que $f$ y $g$ son \emph{ortogonales} si
    \[\int_a^b fg = 0.\]
\end{definition}

\begin{definition}
    Sea $\{\psi_k\}_{k=1}^\infty$ una sucesión de elementos de $L^2([a,b])$ con $\psi_k \neq 0$ para todo $k \in \N$. Se dice que $\{\psi_k\}_{k=1}^\infty$ es un \emph{sistema ortogonal en $L^2([a,b])$} si para todos $k,l \in N$ con $\psi_k \neq \psi_l$ se tiene que
    \[\int_a^b \psi_k\psi_l = 0.\]
    Si además $||\psi_k||_2 = 1$ para todo $k \in \N$, se dice que $\{\psi_k\}_{k=1}^\infty$ es un \emph{sistema ortonormal en $L^2([a,b])$}.
\end{definition}

Es claro que si $\{\psi_k\}_{k=1}^\infty$ es un sistema ortogonal, entonces $\{\frac{1}{||\psi_k||_2}\psi_k\}_{k=1}^\infty$ es un sistema ortonormal.

Evidentemente, todo lo anterior sigue siendo válido para sucesiones de la forma $\{\psi_k\}_{k=k_0}^\infty$, con $k_0 \in \Z$.

\begin{proposition}
    Para cada $k \in \N$, sea
    \begin{align*}
        \psi_k \colon [0,L] &\longrightarrow \R \\
        x &\longmapsto \sen\left(\frac{k\pi}{L}x \right)
    \end{align*}
    Entonces $\{\psi_k\}_{k=1}^\infty$ es un sistema ortogonal en $L^2([0,L])$.
\end{proposition}

\begin{proof}
Usando que para $\alpha,\beta\in \R$ cualesquiera se verifica
\[\cos(\alpha+\beta) = \cos(\alpha)\cos(\beta)-\sen(\alpha)\sen(\beta), \qquad \cos(\alpha-\beta) = \cos(\alpha)\cos(\beta)+\sen(\alpha)\sen(\beta),\]    
se obtiene que para $k,l \in \N$ con $k \neq l$,
\begin{align*}
\int_0^L\sen\left(\frac{k\pi}{L}x\right)\sen\left(\frac{l\pi}{L}x\right) \, dx  &=\frac{1}{2}\int_0^L\cos\left(\frac{k\pi}{L}x -\frac{l\pi}{L}x\right) \, dx-\frac{1}{2}\int_0^L\cos\left(\frac{k\pi}{L}x +\frac{l\pi}{L}x\right) \, dx \\
&=\frac{1}{2}\int_0^L\cos\left(\frac{(k-l)\pi}{L}x\right) \, dx-\frac{1}{2}\int_0^L\cos\left(\frac{(k+l)\pi}{L}x\right) \, dx \\
&=\frac{1}{2}\left[\frac{L\sen(\frac{(k-l)\pi}{L}x)}{(k-l)\pi}\right]_{x=0}^{x=L}-\frac{1}{2}\left[\frac{L\sen(\frac{(k+l)\pi}{L}x)}{(k+l)\pi}\right]_{x=0}^{x=L} \\
&= 0. \qedhere
\end{align*} 
\end{proof}

\begin{proposition}
    Para cada $k \in \N \cup \{0\}$, sea
    \begin{align*}
        \psi_k \colon [0,L] &\longrightarrow \R \\
        x &\longmapsto \cos\left(\frac{k\pi}{L}x \right)
    \end{align*}
    Entonces $\{\psi_k\}_{k=0}^\infty$ es un sistema ortogonal en $L^2([0,L])$.
\end{proposition}

\begin{proof}
    Extremadamente similar a la de la proposición anterior.
\end{proof}

\begin{proposition}
    Para cada $k \in \N \cup \{0\}$, sea
    \[
        \begin{aligned}[t]
            \psi_{2k} \colon [0,L] &\longrightarrow \R \\
            x &\longmapsto \cos\left(\frac{k\pi}{L}x \right)
        \end{aligned}
        \qquad \qquad
        \begin{aligned}[t]
            \psi_{2k-1} \colon [0,L] &\longrightarrow \R \\
            x &\longmapsto \sen\left(\frac{k\pi}{L}x \right)
        \end{aligned}
    \]
    Entonces $\{\psi_k\}_{k=0}^\infty$ es un sistema ortogonal en $L^2([-L,L])$.
\end{proposition}

\begin{proof}
    Extremadamente similar a la de la proposición anterior; ahora también hay que usar que 
    \[\sen(\alpha+\beta) = \sen(\alpha)\cos(\beta)+\cos(\alpha)\sen(\beta), \qquad \sen(\alpha-\beta) = \sen(\alpha)\cos(\beta)-\cos(\alpha)\sen(\beta)\]   
    para $\alpha,\beta\in\R$ cualesquiera. 
\end{proof}

En adelante, los sistemas ortogonales de las proposiciones anteriores se van a escribir de forma más abreviada como $\{\sen(\frac{k\pi}{L}\, \cdot \,)\}_{k=1}^\infty$, $\{1,\cos(\frac{k\pi}{L}\, \cdot \,)\}_{k=1}^\infty$ y $\{1,\cos(\frac{k\pi}{L}\, \cdot \,),\sen(\frac{k\pi}{L}\, \cdot \,)\}_{k=1}^\infty$, y se van a denominar \emph{sistema de senos}, \emph{sistema de cosenos} y \emph{sistema trigonométrico}, respectivamente.

\section{Sistemas ortogonales completos}

Una vez introducidos los sistemas ortogonales, puede generalizarse la pregunta que motiva este apéndice: si $\{\psi_k\}_{k=1}^\infty$ es un sistema ortogonal en $L^2([a,b])$, ¿existe una sucesión $\{\alpha_k\}_{k=1}^\infty$ de números reales tal que
\[f(x)=\sum_{k=1}^\infty \alpha_k \psi_k(x)\]
para todo $x \in [a,b]$?

Se adelanta que la respuesta a esta pregunta no va a ser siempre afirmativa, pero todo va a funcionar mejor si en lugar de preguntarse sobre la convergencia puntual de la serie anterior, se considera la convergencia de la serie en $||\cdot||_2$. Cabe plantearse entonces si existe una sucesión $\{\alpha_k\}_{k=1}^\infty$ de números reales tal que
\[\biggl|\biggl|f-\sum_{k=1}^n \alpha_k\psi_k\biggr|\biggr|_2 \nconv 0.\]
En caso de que la serie converja, veamos quiénes tienen que ser los $\alpha_k$, $k \in \N$. Por la desigualdad de Schwarz, para todos $k,l\in \N$ con $k \neq l$ se tiene
\[\biggl\langle \psi_l, f-\sum_{k=1}^n\alpha_k\psi_k \biggr\rangle \leq ||\psi_l||_2\biggl|\biggl|f-\sum_{k=1}^n\alpha_k\psi_k\biggr|\biggr|_2\]
para cada $n \in \N$, luego 
\[\biggl\langle \psi_l, f-\sum_{k=1}^n\alpha_k\psi_k \biggr\rangle \nconv 0.\]
Ahora bien, para cada $n \in \N$ con $n \geq l$,
\[\biggl\langle \psi_l, f-\sum_{k=1}^n\alpha_k\psi_k \biggr\rangle = \langle \psi_l,f \rangle - \sum_{k=1}^n \alpha_k \langle\psi_l,\psi_k\rangle =  \langle \psi_l,f \rangle - \alpha_l \langle\psi_l,\psi_l\rangle =  \langle \psi_l,f \rangle - \alpha_l||\psi_l||_2^2,\]
luego debe tenerse
\[ \langle \psi_l,f \rangle - \alpha_l||\psi_l||_2^2 = 0,\]
es decir,
\[\alpha_l = \frac{\langle\psi_l,f\rangle}{||\psi_l||_2^2} = \frac{\int_a^b \psi_l f}{\int_a^b \psi_l^2}.\]

\begin{definition}
    Sea $\{\psi_k\}_{k=1}^\infty$ un sistema ortogonal en $L^2([a,b])$ y sea $f \in L^2([a,b])$. Los números reales
    \[\alpha_k(f) =  \frac{\int_a^b f\psi_l }{\int_a^b \psi_l^2}, \qquad k \in \N,\]
    se dice que son los \emph{coeficientes de Fourier de $f$ en el sistema $\{\psi_k\}_{k=1}^\infty$}, y se denota
    \[f \sim \sum_{k=1}^\infty \alpha_k(f)\psi_k.\]
    La serie $\sum_{k=1}^\infty \alpha_k(f)\psi_k$ se conoce como \emph{serie de Fourier de $f$ en el sistema $\{\psi_k\}_{k=1}^\infty$}.
\end{definition}

\begin{definition}
    Un sistema ortogonal $\{\psi_k\}_{k=1}^\infty$ en $L^2([a,b])$ se dice que es \emph{completo} si para toda $f \in L^2([a,b])$ se tiene que
    \[\biggl|\biggl|f-\sum_{k=1}^n \alpha_k(f)\psi_k\biggr|\biggr|_2 \nconv 0.\]
\end{definition}

\begin{proposition}
    Sean $f,g \in L^2([a,b])$, $\lambda \in \R$ y $k \in \N$. Entonces
    \[\alpha_k(f+g) = \alpha_k(f)+\alpha_k(g), \qquad \qquad \alpha_k(\lambda f) =\lambda\alpha_k(f). \]
\end{proposition}

\begin{proof}
    Consecuencia directa de la linealidad de la integral.
\end{proof}

\begin{theorem}
    Sea $\{\psi_k\}_{k=1}^\infty$ un sistema ortogonal en $L^2([a,b])$, sea $f \in L^2([a,b])$, sea $n \in \N$ y sean $\beta_1,\mathellipsis,\beta_n \in \R$. Entonces
    \[\biggl|\biggl|f-\sum_{k=1}^n \beta_k\psi_k\biggr|\biggr|_2^2 = ||f||_2^2 +\sum_{k=1}^n (\beta_k-\alpha_k(f))^2||\psi_k||_2^2 -\sum_{k=1}^n \alpha_k(f)^2||\psi_k||_2^2.\]
\end{theorem}

\begin{proof}
    
\end{proof}

\begin{corollary}\label{cor:A.1.9}
    Sea $\{\psi_k\}_{k=1}^\infty$ un sistema ortogonal en $L^2([a,b])$, sea $f \in L^2([a,b])$ y sea $n \in \N$. Entonces
    \[\biggl|\biggl|f-\sum_{k=1}^n \alpha_k(f)\psi_k\biggr|\biggr|_2^2 = ||f||_2^2 -\sum_{k=1}^n \alpha_k(f)^2||\psi_k||_2^2.\]
\end{corollary}

\begin{proof}
    Basta aplicar el teorema anterior con $\beta_k=\alpha_k(f)$ para cada $k \in \{1,\mathellipsis,n\}$.
\end{proof}

\begin{corollary}
    Sea $\{\psi_k\}_{k=1}^\infty$ un sistema ortogonal en $L^2([a,b])$, sea $f \in L^2([a,b])$, sea $n \in \N$ y sean $\beta_1,\mathellipsis,\beta_n \in \R$. Entonces
    \[\biggl|\biggl|f-\sum_{k=1}^n \alpha_k(f)\psi_k\biggr|\biggr|_2 \leq \biggl|\biggl|f-\sum_{k=1}^n \beta_k\psi_k\biggr|\biggr|_2.\]
\end{corollary}

\begin{proof}
    En efecto,
    \begin{align*}
        \biggl|\biggl|f-\sum_{k=1}^n \beta_k\psi_k\biggr|\biggr|_2^2 &=  ||f||_2^2+\sum_{k=1}^n (\beta_k-\alpha_k(f))^2||\psi_k||_2^2 -\sum_{k=1}^n \alpha_k(f)^2||\psi_k||_2^2 \\
        &= \biggl|\biggl|f-\sum_{k=1}^n \alpha_k(f)\psi_k\biggr|\biggr|_2^2  +\underbracket{\sum_{k=1}^n (\beta_k-\alpha_k(f))^2||\psi_k||_2^2}_{\geq0} \\
        &\geq  \biggl|\biggl|f-\sum_{k=1}^n \alpha_k(f)\psi_k\biggr|\biggr|_2^2,
    \end{align*}
    donde en la primera igualdad se ha usado el teorema anterior, y en la segunda, el corolario anterior.
\end{proof}

En términos cotidianos, el resultado anterior afirma que de todas las combinaciones lineales posibles de $\psi_1,\mathellipsis,\psi_n$, la que mejor aproxima a $f$ en $||\cdot||_2$ es la que tiene por coeficientes a los coeficientes de Fourier de $f$.

\begin{corollary}[Desigualdad de Bessel]\label{cor:A.1.11}
    Sea $\{\psi_k\}_{k=1}^\infty$ un sistema ortogonal en $L^2([a,b])$ y sea $f \in L^2([a,b])$. Entonces
    \[\sum_{k=1}^\infty \alpha_k(f)^2||\psi_k||_2^2 \leq ||f||_2^2.\]
\end{corollary}

\begin{proof}
    Por el \hyperref[cor:A.1.9]{\color{gray}Corolario A.1.9},
    \[||f||_2^2 -\sum_{k=1}^n \alpha_k(f)^2||\psi_k||_2^2 = \biggl|\biggl|f-\sum_{k=1}^n \alpha_k(f)\psi_k\biggr|\biggr|_2^2 \geq 0,\]
    de donde se obtiene la igualdad del enunciado.
\end{proof}

\begin{corollary}[Lema de Riemann-Lebesgue]\label{cor:A.2.8}
    Sea $\{\psi_k\}_{k=1}^\infty$ un sistema ortogonal en $L^2([a,b])$ y sea $f \in L^2([a,b])$. Entonces
    \[\alpha_k(f)||\psi_k||_2 \kconv 0. \]
\end{corollary}

\begin{proof}
    Basta tener en cuenta que, por el resultado anterior, la serie $\sum_{k=1}^\infty \alpha_k^2||\psi_k||_2^2$ es convergente.
\end{proof}

\begin{corollary}
    Si $\{\psi_k\}_{k=1}^\infty$ es un sistema ortogonal en $L^2([a,b])$ y $f \in L^2([a,b])$, entonces
    \[\biggl|\biggl|f-\sum_{k=1}^n \alpha_k(f)\psi_k\biggr|\biggr|_2 \nconv 0 \qquad \iff \qquad ||f||_2^2 = \sum_{k=1}^\infty \alpha_k(f)^2||\psi_k||_2^2.\]
\end{corollary}

\begin{proof}
    Utilizando el \hyperref[cor:A.1.9]{\color{gray}Corolario A.1.9},
    \[\biggl|\biggl|f-\sum_{k=1}^n \alpha_k(f)\psi_k\biggr|\biggr|_2 \nconv 0 \qquad \iff \qquad ||f||_2^2 -\sum_{k=1}^n \alpha_k(f)^2||\psi_k||_2^2 \nconv 0.\]
    Ahora basta tener en cuenta que por \hyperref[cor:A.1.11]{\color{gray}desigualdad de Bessel}, la serie $\sum_{k=1}^\infty \alpha_k(f)^2||\psi_k||_2^2$ converge.
\end{proof}

\begin{corollary}\label{cor:A.2.10}
    Un sistema ortogonal $\{\psi_k\}_{k=1}^\infty$ en $L^2([a,b])$ es completo si y solo si para toda $f \in L^2([a,b])$ se tiene que
    \[||f||_2^2 = \sum_{k=1}^\infty \alpha_k(f)^2||\psi_k||_2^2.\]
\end{corollary}

\begin{proof}
    Consecuencia inmediata del corolario anterior.
\end{proof}

La igualdad que protagoniza este corolario se conoce como \emph{igualdad de Parseval}. En caso de que $\{\psi_k\}_{k=1}^\infty$ sea un sistema ortonormal completo en $L^2([a,b])$, esta igualdad dice que
\[||f||_2^2 = \sum_{k=1}^\infty \alpha_k(f)^2\]
para toda $f \in L^2([a,b])$. En la práctica, esta fórmula resultará extremadamente útil para calcular la suma de muchas series.

\begin{corollary}
    Un sistema ortogonal $\{\psi_k\}_{k=1}^\infty$ en $L^2([a,b])$ es completo si y solo si para cada $f \in L^2([a,b])$ se verifica lo siguiente:
    \[\int_a^b f \psi_k = 0 \textup{ para todo } k \in \N \qquad \implies \qquad f = 0 \textup{ en casi todo punto.}\]
\end{corollary}

\begin{proof}
    Se deja como ejercicio (una de las implicaciones es consecuencia directa del corolario anterior; la otra no es tan directa pero sigue siendo fácil).
\end{proof}

Si se considera el sistema trigonométrico en $L^2([-\pi,\pi])$, que se recuerda que es $\{1,\cos(k\, \cdot \,),\sen(k\, \cdot \,)\}_{k=1}^\infty$, es fácil comprobar que
\[f \sim \frac{a_0(f)}{2}+\sum_{k=1}^\infty (a_k(f)\cos(k\, \cdot \,) + b_k(f)\sen(k\, \cdot \,)),\]
donde, para cada $k \in \N$,
\[a_k(f) = \frac{1}{\pi}\int_{-\pi}^\pi f(x)\cos(kx)\, dx, \qquad b_k(f) = \frac{1}{\pi}\int_{-\pi}^\pi f(x)\sen(kx) \, dx,\]
mientras que
\[a_0(f) = \frac{1}{\pi}\int_{-\pi}^\pi f(x) \, dx.\]

Cuando se habla de \emph{coeficientes de Fourier} o \emph{series de Fourier} sin hacer referencia a ningún sistema ortogonal, se entiende que el sistema ortogonal considerado es el sistema trigonométrico.

Cuando se habla de \emph{coeficientes de Fourier de senos} o \emph{series de Fourier de senos} sin hacer referencia a ningún sistema ortogonal, se entiende que el sistema ortogonal considerado es el sistema de senos; lo mismo para el sistema de cosenos.

\begin{theorem}
    El sistema de senos en $L^2([0,L])$ es completo.
\end{theorem}

\begin{theorem}
    El sistema de cosenos en $L^2([0,L])$ es completo.
\end{theorem}

Gracias a estos resultados, se puede afirmar que si $f \in L^2([0,L])$ (esto no es pedir demasiado; basta, por ejemplo, con que $f$ sea continua), entonces
\[ \biggl|\biggl|f - \frac{a_0(f)}{2}-\sum_{k=1}^n a_k(f)\cos\left(\frac{k\pi}{L}\, \cdot \,\right)\biggr|\biggr|_2 \nconv 0, \qquad \biggl|\biggl|f - \sum_{k=1}^n b_k(f)\sen\left(\frac{k\pi}{L}\, \cdot \,\right)\biggr|\biggr|_2 \nconv 0.\]
Si en lugar de convergencia en $||\cdot||_2$ se tuviese convergencia puntual, se habrían alcanzado los objetivos de este tema y se podría volver al estudio de las ecuaciones en derivadas parciales. Por desgracia, la convergencia en $||\cdot||_2$ no implica la convergencia puntual, así que habrá que seguir trabajando con series de Fourier.

\begin{theorem}
    El sistema trigonométrico en $L^2([-L,L])$ es completo.
\end{theorem}

\section{Convergencia puntual de series de Fourier}

En esta sección se trabajará con el sistema trigonométrico en $L^2([-\pi,\pi])$. Si $f \in L^2([-\pi,\pi])$ se trata de estudiar de una vez por todas bajo qué condiciones se tiene que
\[f(x) = \frac{a_0(f)}{2}+\sum_{k=1}^\infty (a_k(f)\cos(kx) + b_k(f)\sen(kx))\]
para todo $x \in [-\pi,\pi]$ (o por lo menos para unos cuantos), siendo 
\[a_k(f) = \frac{1}{\pi}\int_{-\pi}^\pi f(x)\cos(kx)\, dx\] para cada $k \in \N \cup \{0\}$, y \[b_k(f) = \frac{1}{\pi}\int_{-\pi}^\pi f(x)\sen(kx) \, dx\]
para cada $k \in \N$. Es decir, se trata de estudiar la convergencia puntual de la sucesión de números reales $\{S_nf(x)\}_{n=1}^\infty$, donde, para cada $x \in [-\pi,\pi]$ y cada $n \in \N$,
\[S_nf(x) = \frac{a_0(f)}{2}+\sum_{k=1}^n (a_k(f)\cos(kx) + b_k(f)\sen(kx)).\]
Obsérvese que los coeficientes $a_k(f)$ y $b_k(f)$ también tienen sentido si $f \in L^1([-\pi,\pi])$, así que puede definirse la serie de Fourier de una función de $L^1([-\pi,\pi])$ de la misma manera que para funciones de $L^2([-\pi,\pi])$.

En adelante, si $f \colon [-\pi,\pi] \to \R$, se denotará por $\widetilde{f}$ a la extensión $2\pi$-periódica de $f |_{[-\pi,\pi)}$ a todo $\R$.

\begin{theorem}[Lema de Riemann-Lebesgue]
    Sea $f \in L^1([-\pi,\pi])$. Entonces
    \[a_k(f) \kconv 0, \qquad \qquad b_k(f) \kconv 0.\]
\end{theorem}

\begin{theorem}[Criterio de Dini]\label{dini}
    Sea $f \in L^1([-\pi,\pi])$ y sea $x \in [-\pi,\pi]$. Si existen $A \in \R$ y $\delta \in (0,\pi)$ tales que
    \[\int_{-\delta}^\delta \left|\frac{\widetilde{f}(x+\xi)-A}{\xi}\right| \, d\xi < \infty,\]
    entonces $\{S_nf(x)\}_{n=1}^\infty$ converge a $A$, es decir, 
    \[\frac{a_0(f)}{2}+\sum_{k=1}^\infty (a_k(f)\cos(kx) + b_k(f)\sen(kx)) = A.\]
\end{theorem}

A continuación se estudian algunas condiciones más manejables que permitan utilizar el teorema anterior.

\begin{corollary}
    Sea $f \in L^1([-\pi,\pi])$ y sea $x \in [-\pi,\pi]$. Si $\widetilde{f}$ es derivable en $x$, entonces
    \[\frac{a_0(f)}{2}+\sum_{k=1}^\infty (a_k(f)\cos(kx) + b_k(f)\sen(kx)) = f(x).\]
\end{corollary}

\begin{proof}
    Como la función $\xi \mapsto \left|\frac{\widetilde{f}(x+\xi)-f(x)}{\xi}\right|$ tiene límite cuando $\xi \to 0$, entonces existen $\delta > 0$ (se puede suponer que $\delta < \pi$) y $M>0$ tales que
    \[\left|\frac{\widetilde{f}(x+\xi)-f(x)}{\xi}\right| \leq M\]
    para todo $\xi \in (-\delta,\delta)$, así que basta aplicar el \hyperref[dini]{\color{gray}criterio de Dini} con $A = f(x)$.
\end{proof}

\begin{corollary}
    Sea $f \in L^1([-\pi,\pi])$ y sea $x \in [-\pi,\pi]$. Si $\widetilde{f}$ es de Lipschitz en un entorno de $x$, entonces
    \[\frac{a_0(f)}{2}+\sum_{k=1}^\infty (a_k(f)\cos(kx) + b_k(f)\sen(kx)) = f(x).\]
\end{corollary}

\begin{proof}
    Igual de inmediata que la anterior.
\end{proof}

\begin{corollary}
    Sea $f \in L^1([-\pi,\pi])$ y sea $x \in [-\pi,\pi]$. Si $\widetilde{f}$ es continua en $x$ y de clase $1$ a trozos en un entorno de $x$, entonces
    \[\frac{a_0(f)}{2}+\sum_{k=1}^\infty (a_k(f)\cos(kx) + b_k(f)\sen(kx)) = f(x).\]
\end{corollary}

\begin{proof}
    Se deja como ejercicio (utilícese el teorema del valor medio).
\end{proof}

\begin{corollary}
    Sea $f \in L^1([-\pi,\pi])$. Si $f$ es continua, de clase $1$ a trozos y tal que $f(\pi) = f(-\pi)$, entonces
    \[\frac{a_0(f)}{2}+\sum_{k=1}^\infty (a_k(f)\cos(kx) + b_k(f)\sen(kx)) = f(x)\]
    para todo $x\in [-\pi,\pi]$.
\end{corollary}

\begin{proof}
    Consecuencia directa el corolario anterior, teniendo en cuenta que $\widetilde{f}$ es continua en $\pi$ y $-\pi$ si y solo si $f(\pi) = f(-\pi)$.
\end{proof}

La condición $f(\pi) = f(-\pi)$ quizá sea demasiado restrictiva. Si esto no se verifica, todavía se puede decir algo sobre la convergencia puntual de la serie de Fourier de $f$, como muestra el siguiente resultado:

\begin{theorem}[Teorema de Dirichlet]
    Sea $f \in L^1([-\pi,\pi])$. Si $f$ es de clase $1$ a trozos, entonces
    \[\frac{a_0(f)}{2}+\sum_{k=1}^\infty (a_k(f)\cos(kx) + b_k(f)\sen(kx)) = \frac{\widetilde{f}(x^-)+\widetilde{f}(x^+)}{2}\]
    para todo $x \in [-\pi,\pi]$.
\end{theorem}

Nótese que si $x \in (-\pi,\pi)$, entonces $\frac{\widetilde{f}(x^-)+\widetilde{f}(x^+)}{2} = \frac{{f}(x^-)+{f}(x^+)}{2}$, y si $x \in \{-\pi,\pi\}$, entonces $\frac{\widetilde{f}(x^-)+\widetilde{f}(x^+)}{2} = \frac{{f}(-\pi^+)+{f}(\pi^-)}{2}$.

\section{Convergencia uniforme de series de Fourier}

\begin{proposition}
    Sea $f \in L^1([-\pi,\pi])$. Si $f$ es continua, de clase $1$ a trozos y tal que $f(\pi) = f(-\pi)$, entonces
    \[a_k(f')=kb_k(f), \qquad \qquad b_k(f') = -ka_k(f)\]
    para todo $k \in \N$, mientras que $a_0(f')=0$.
\end{proposition}

\begin{proof}
    
\end{proof}

En otros términos, este resultado dice que si $f \colon [-\pi,\pi] \to \R$ es continua, de clase $1$ a trozos y tal que $f(\pi) = f(-\pi)$, entonces la serie de Fourier de $f'$ se obtiene derivando término a término la de $f$.

Es fácil probar que por ser $f$ de clase $1$ a trozos, se tiene que $f' \in L^2([-\pi,\pi]) \subset L^1([-\pi,\pi])$ y por tanto está definida su serie de Fourier.

Antes de enunciar el siguiente resultado, se recuerda que si $f \in L^1([-\pi,\pi])$ y $n \in \N$, $S_nf \colon [-\pi,\pi] \to \R$ es la función dada por
\[S_nf(x) = \frac{a_0(f)}{2}+\sum_{k=1}^n (a_k(f)\cos(kx) + b_k(f)\sen(kx)).\]

\begin{theorem}\label{teo:A.4.2}
    Sea $f \in L^1([-\pi,\pi])$ continua, de clase $1$ a trozos y con $f(\pi) = f(-\pi)$. Entonces $\{S_nf\}_{n=1}^\infty$ converge uniformemente a $f$.
\end{theorem}

\begin{proof}
    El objetivo es utilizar el criterio de Weierstrass. Por la proposición anterior, se tiene que
    \[|a_k(f)| = \frac{1}{k}|b_k(f')| \qquad \textup{y} \qquad |b_k(f)| = \frac{1}{k}|a_k(f')|\]
    para todo $k \in \N$. Usando que $\alpha\beta \leq \frac{1}{2}(\alpha^2+\beta^2)$ para todos $\alpha,\beta \in \R$,
    \[|a_k(f)| \leq \frac{1}{2}\left(\frac{1}{k^2}+b_k(f')^2\right) \qquad \textup{y} \qquad |b_k(f)| \leq\frac{1}{2}\left( \frac{1}{k^2}+a_k(f')^2\right)\]
    para todo $k \in \N$. Ahora bien, como $f' \in L^2([-\pi,\pi])$ por ser $f$ de clase $1$ a trozos, por la \hyperref[cor:A.1.11]{\color{gray}desigualdad de Bessel},
    \[\sum_{k=1}^\infty b_k(f')^2 < \infty \qquad \textup{y} \qquad \sum_{k=1}^\infty a_k(f')^2 < \infty.\]
    Por tanto, por las desigualdades anteriores,
    \[\sum_{k=1}^\infty |a_k(f)| < \infty \qquad \textup{y} \qquad \sum_{k=1}^\infty |b_k(f)| < \infty.\]
    Ahora bien, para todo $n \in \N$ y todo $x \in [-\pi,\pi]$ se tiene que
    \[|S_nf(x)| \leq \biggl|\frac{a_0(f)}{2}\biggr|+\sum_{k=1}^n (|a_k(f)|+|b_k(f)|),\]
    y como $\sum_{k=1}^\infty (|a_k(f)|+|b_k(f)|) < \infty$, el criterio de Weierstrass permite afirmar que $\{S_nf\}_{n=1}^\infty$ converge uniformemente a $f$.
\end{proof}

De nuevo, la condición $f(-\pi) = f(\pi)$ puede resultar demasiado restrictiva, así que se enuncia sin demostración un resultado más potente que el anterior:

\begin{theorem}
    Sea $f \in L^1([-\pi,\pi])$ continua y de clase $1$ a trozos en $[a,b] \subset [-\pi,\pi]$. Entonces $\{S_nf\}_{n=1}^\infty$ converge uniformemente a $f$ en $[a+\delta,b-\delta]$ para todo $\delta \in (0,\frac{b-a}{2})$.
\end{theorem}

\section{Series de Fourier de senos y cosenos}

En esta sección se trabajará con el sistema de senos y el de cosenos en $L^2([0,\pi])$. Si $f \in L^2([0,\pi])$, es fácil probar que en el sistema de cosenos,
\[f \sim \frac{a_0}{2}+\sum_{k=1}^\infty a_k(f)\cos(k \, \cdot \,),\]
donde
\[a_k(f) = \frac{2}{\pi}\int_0^\pi f(x)\cos(kx) \, dx\]
para cada $k \in \N \cup \{0\}$, mientras que en el sistema de senos,
\[f \sim \sum_{k=1}^\infty b_k(f)\sen(k\, \cdot \,),\]
donde
\[b_k(f) = \frac{2}{\pi}\int_0^\pi f(x)\sen(kx) \, dx\]
para cada $k \in \N$. Como estos coeficientes siguen teniendo sentido si $f \in L^1([-\pi,\pi])$, se extienden las definiciones de \emph{serie de Fourier de cosenos} y \emph{serie de Fourier de senos} para funciones de $L^1([0,\pi])$.

El objetivo es estudiar la convergencia puntual y uniforme de series de Fourier de senos y cosenos utilizando lo visto en las dos secciones anteriores. 

Se trabajará en primer lugar con la serie de senos. Sea $f \in L^1([0,\pi])$. Obsérvese que si se define $f^{(\textup{imp})} \colon [-\pi,\pi] \to \R$ mediante
\[f^{(\textup{imp})}(x) = \begin{cases}
    f(x) & $ si $ 0 \leq x \leq \pi, \\
    -f(-x) & $ si $ -\pi \leq x < 0,
\end{cases}\]
se tiene que $f^{(\textup{imp})} \in L^1([-\pi,\pi])$ y la serie de Fourier de $f^{(\textup{imp})}$ en el sistema trigonométrico coincide con la serie de Fourier de senos de $f$.

\begin{corollary}
    Sea $f \in L^1([0,\pi])$ continua, de clase $1$ a trozos y con $f(0) = f(\pi) = 0$. Entonces la serie de Fourier de senos de $f$ converge uniformemente a $f$.
\end{corollary}

\begin{proof}
    Basta aplicar el \hyperref[teo:A.4.2]{\color{gray}teorema A.4.2} a $f^{(\textup{imp})}$ teniendo en cuenta que:
    \begin{itemize}
    \item $f^{(\textup{imp})}$ es continua en 0 si y solo si $f(0) = 0$.
    \item $f^{(\textup{imp})}(-\pi) = f^{(\textup{imp})}(\pi)$ si y solo si $f(\pi) = 0$.
    \item La serie de Fourier de $f^{(\textup{imp})}$ en el sistema trigonométrico coincide con la serie de Fourier de senos de $f$. \qedhere
    \end{itemize} 
\end{proof}

Ahora se razona análogamente con la serie de cosenos: si $f \in L^1([0,\pi])$, se define $f^{(\textup{par})} \colon [-\pi,\pi] \to \R$ mediante
\[f^{(\textup{par})}(x) = \begin{cases}
    f(x) & $ si $ 0 \leq x \leq \pi, \\
    f(-x) & $ si $ -\pi \leq x < 0,
\end{cases}\]
y resulta que $f^{(\textup{par})} \in L^1([-\pi,\pi])$ y la serie de Fourier de $f^{(\textup{par})}$ en el sistema trigonométrico coincide con la serie de Fourier de cosenos de $f$.

\begin{corollary}
    Sea $f \in L^1([0,\pi])$ continua y de clase $1$ a trozos. Entonces la serie de Fourier de cosenos de $f$ converge uniformemente a $f$.
\end{corollary}

\begin{proof}
    Basta aplicar el \hyperref[teo:A.4.2]{\color{gray}teorema A.4.2} a $f^{(\textup{par})}$ teniendo en cuenta que:
    \begin{itemize}
    \item $f^{(\textup{par})}$ es continua en 0 porque $f$ es continua en $0$ por la derecha.
    \item $f^{(\textup{par})}(-\pi) = f^{(\textup{par})}(\pi)$ por definición de $f^{(\textup{par})}$.
    \item La serie de Fourier de $f^{(\textup{par})}$ en el sistema trigonométrico coincide con la serie de Fourier de senos de $f$. \qedhere
    \end{itemize} 
\end{proof}

Todo esto puede extenderse sin trabajar demasiado a intervalos arbitrarios de $\R$. Se enuncian, por ejemplo, los resultados siguientes:

\begin{proposition}
    Sea $f \in L^1([0,\pi])$ continua, de clase $1$ a trozos y con $f(0) = f(L) = 0$. Para cada $k \in \N$, sea
    \[b_k(f) = \frac{2}{L}\int_0^L f(x)\sen\left(\frac{k\pi}{L}x\right) \, dx.\]
    Entonces para todo $x \in [0,L]$ se tiene que
    \[f(x)=\sum_{k=1}^\infty b_k(f)\sen\left(\frac{k\pi}{L}x\right),\]
    y además, la serie converge uniformemente a $f$ en $[0,L]$.
\end{proposition}

\begin{proposition}
    Sea $f \in L^1([0,\pi])$ continua y de clase $1$ a trozos. Para cada $k \in \N \cup \{0\}$, sea
    \[a_k(f) = \frac{2}{L}\int_0^L f(x)\cos\left(\frac{k\pi}{L}x\right) \, dx.\]
    Entonces para todo $x \in [0,L]$ se tiene que
    \[f(x)=\frac{a_0(f)}{2}+\sum_{k=1}^\infty a_k(f)\cos\left(\frac{k\pi}{L}x\right),\]
    y además, la serie converge uniformemente a $f$ en $[0,L]$.
\end{proposition}

\chapter{Transformada de Fourier}\label{B}

\section{Definición y propiedades elementales}

\begin{definition}
    Si $f \in L^1(\R)$, la \emph{transformada de Fourier de $f$} no es más que la función $\widehat{f} \colon \R \to \C$ dada por
    \[\widehat{f}(\xi) = \frac{1}{\sqrt{2\pi}}\int_\R f(x)e^{-i\xi x} \, dx.\]
\end{definition}

Es claro que la integral anterior tiene sentido, es decir, que la función $x \mapsto f(x)e^{-i\xi x}$, $x \in \R$, es medible e integrable.

La constante que multiplica a la integral va a causar grandes estragos, estropeando algunas fórmulas que quedarían más limpias si se definiese la transformada de Fourier de otra manera ligeramente distinta. Esto es lo que hay.

Se recogen en la proposición que sigue las propiedades más relevantes de la transformada de Fourier. Antes, se introduce la notación siguiente: si $a \in \R$, se definen las funciones $\tau_af\colon \R \to \C$ y $\delta_af \colon \R \to \C$ mediante
\[\tau_af(x) = f(x-a), \qquad \qquad \qquad \delta_af(x)=f(ax).\]

\begin{proposition}\label{pro:B.1.2}
    Sea $f \in L^1(\R)$. Se verifican las siguientes propiedades:
    \begin{enumerate}
        \item $\widehat{f}$ es acotada y uniformemente continua.
        \item Si $g \in L^1(\R)$ y $\alpha \in \C$, entonces \[\widehat{f+g} = \widehat{f}+\widehat{g}, \qquad \qquad \widehat{\alpha f} = \alpha \widehat{f}.\]
        \item Si $a \in \R$, entonces $\tau_af \in L^1(\R)$ y \[\widehat{\tau_af}(\xi) = e^{-ia\xi}\widehat{f}(\xi).\]
        \item Si $a \in \R$ y $g \colon \R \to \R$ es la función dada por $g(x)= e^{iax}f(x)$, entonces \[\tau_a\widehat{f}(\xi) = \widehat{g}(\xi).\]
        \item Si $a > 0$, entonces $\delta_af \in L^1(\R)$ y
        \[\widehat{\delta_af}(\xi) = \frac{1}{a}\widehat{f}\left(\frac{1}{a}\xi\right).\]
        \item Si $f$ es continua y de clase $1$ a trozos y $f' \in L^1(\R)$, entonces \[\widehat{f'}(\xi) = i\xi \widehat{f}(\xi).\]
        \item Si la función $g \colon \R \to \R$ dada por $g(x)=xf(x)$ es de $L^1(\R)$, entonces $\widehat{f}$ es derivable y \[(\widehat{f})'(\xi) = -i\widehat{g}(\xi).\]
        \item Si $g \in L^1(\R)$, entonces $\widehat{f}g,f\widehat{g} \in L^1(\R)$ y
        \[\int_\R \widehat{f}(x)g(x) \, dx = \int_\R f(x)\widehat{g}(x) \, dx.\]
    \end{enumerate}
\end{proposition}

\begin{proof}
    \hfill
    \begin{enumerate}
        \item Para todo $\xi \in \R$,
        \[|\widehat{f}(\xi)| \leq \frac{1}{\sqrt{2\pi}} \int_\R |f(x)e^{-i\xi x}| \, dx = \frac{1}{\sqrt{2\pi}}\int_\R |f(x)| \, dx = \frac{||f||_1}{\sqrt{2\pi}},\]
        luego $\widehat{f}$ es acotada. Para probar que $\widehat{f}$ es uniformemente continua, tómense dos sucesiones $\{\xi_k\}_{k=1}^\infty$ y $\{\eta_k\}_{k=1}^\infty$ tales que $\xi_k-\eta_k \kconv 0$. Para todo $k \in \N$ se tiene
        \begin{align*}
            |\widehat{f}(\xi_k) - \widehat{f}(\eta_k)| &=\frac{1}{\sqrt{2\pi}} \biggl|\int_\R f(x)(e^{i\xi_k x}-e^{i\eta_k x}) \, dx\biggr| \\
            &\leq \frac{1}{\sqrt{2\pi}} \int_\R |f(x)||e^{i\xi_k x} - e^{i\eta_kx}| \, dx \\
            &= \frac{1}{\sqrt{2\pi}} \int_\R |f(x)||e^{i\xi_kx}||1 - e^{i(\eta_k-\xi_k)x}| \, dx \\
            &= \frac{1}{\sqrt{2\pi}} \int_\R |f(x)||1 - e^{i(\eta_k-\xi_k)x}| \, dx.
        \end{align*}
        Veamos que
        \[\lim_{k \to \infty} \int_\R |f(x)||1 - e^{i(\eta_k-\xi_k)x}| = 0, \]
        lo que probará que $\widehat{f}$ es uniformemente continua. Como para todo $k \in \N$ y todo $x \in \R$ se tiene que
        \[|f(x)||1-e^{i(\eta_k-\xi_k)x}| \leq |f(x)|(1+|e^{i(\eta_k-\xi_k)x}|) = 2|f(x)|\]
        y $2f \in L^1(\R)$, por el teorema de la convergencia dominada,
        \[\lim_{k \to \infty} \int_\R |f(x)||1 - e^{i(\eta_k-\xi_k)x}|\, dx =\int_\R \lim_{k \to \infty} |f(x)||1 - e^{i(\eta_k-\xi_k)x}| \, dx = 0. \]
        \item Es consecuencia inmediata de la linealidad de la integral.
        \item Es claro que $\tau_af \in L^1(\R)$. Además, para todo $\xi \in \R$,
        \[\widehat{\tau_af}(\xi) = \frac{1}{\sqrt{2\pi}} \int_\R f(x-a)e^{-i\xi x} \, dx = \frac{1}{\sqrt{2\pi}}\int_\R f(y)e^{-i\xi(y+a)} \, dy = e^{-ia \xi}\widehat{f}(\xi),\]
        realizándose en la segunda igualdad el cambio de variable $x-a = y$, $dx = dy$.
        \item Para todo $\xi \in \R$,
        \[\tau_a\widehat{f}(\xi) = \widehat{f}(\xi-a) = \frac{1}{\sqrt{2\pi}}\int_\R f(x)e^{-i(\xi-a)x} \, dx = \frac{1}{\sqrt{2\pi}}\int_\R g(x)e^{-i\xi x} \, dx = \widehat{g}(x).\]
    \end{enumerate}
    El resto de propiedades se quedan sin demostrar.
\end{proof}

\begin{theorem}[Lema de Riemann-Lebesgue]
    Si $f \in L^1(\R)$, entonces
    \[\lim_{|\xi| \to \infty} \widehat{f}(\xi) = 0.\]
\end{theorem}

\begin{example}
    Sea $f \colon \R \to \R$ la función dada por
    \[f(x)=\begin{cases}
        \cos(x) & $ si $ -\pi < x < \pi, \\
        0 & $ en otro caso$.
    \end{cases}\]
    Veamos que $\widehat{f} \in \mathcal{C}^\infty(\R)$ sin calcular explícitamente $\widehat{f}$. 
    \begin{itemize}
        \item Veamos primero que $\widehat{f} \in \mathcal{C}^1(\R)$. Como la función $g_1 \colon \R \to \C$ dada por
        \[g_1(x)=xf(x) = \begin{cases}
            x\cos(x) & $ si $ -\pi < x < \pi, \\
            0 & $ en otro caso$,
        \end{cases}\]
        pertenece a $L^1(\R)$ (es acotada y de soporte compacto), entonces $\widehat{f}$ es derivable y \[(\widehat{f})'(\xi) = -i\widehat{g_1}(\xi).\] También se tiene que $(\widehat{f})'$ es continua, porque $\widehat{g_1}$ es uniformemente continua. Esto prueba que $\widehat{f} \in \mathcal{C}^1(\R)$.
        \item Veamos ahora que $\widehat{f} \in \mathcal{C}^2(\R)$. Como $(\widehat{f})'(\xi) = -i\widehat{g_1}(\xi)$, basta probar que $\widehat{g_1} \in \mathcal{C}^1(\R)$. La función $g_2 \colon \R \to \C$ dada por
        \[g_2(x)=xg_1(x) = \begin{cases}
            x^2\cos(x) & $ si $ -\pi < x < \pi, \\
            0 & $ en otro caso$,
        \end{cases}\]
        pertenece a $L^1(\R)$ (es acotada y de soporte compacto), luego $\widehat{g_1}$ es derivable y $(\widehat{g_1})'(\xi) = -i\widehat{g_2}(\xi)$. Además, $(\widehat{g_1})'$ es continua, pues $\widehat{g_2}$ es uniformemente continua. Esto prueba que $\widehat{g_1} \in \mathcal{C}^1(\R)$, y por tanto, que $\widehat{f} \in \mathcal{C}^2(\R)$. Además, derivando en $(\widehat{f})'(\xi) = -i\widehat{g_1}(\xi)$, se obtiene
        \[(\widehat{f})''(\xi) = -i(\widehat{g_1})'(\xi) =-i(-i\widehat{g_2}(\xi))= -\widehat{g_2}(\xi).\]
    \end{itemize}
    Por inducción se prueba fácilmente que para todo $k \in \N$, $\widehat{f}$ es $k$ veces derivable y su derivada $k$-ésima es un múltiplo de $\widehat{g_k}$, donde $g_k \colon \R \to \C$ es la función dada por 
    \[g_k(x) = \begin{cases}
        x^k\cos(x) & $ si $ -\pi < x < \pi, \\
        0 & $ en otro caso$,
    \end{cases}\]
    y de aquí se obtiene que $\widehat{f} \in \mathcal{C}^\infty(\R)$.
\end{example}

\section{Convolución}

\begin{definition}
    Si $f,g \in L^1(\R)$ y $x \in \R$, la \emph{convolución de $f$ y $g$ en $x$} se define como
    \[f \ast g(x) = \int_\R f(x-y)g(y) \, dy,\]
    siempre que dicha integral tenga sentido.
\end{definition}

Si $f,g \in L^1(\R)$, no corresponde a esta asignatura probar que para casi todo $x \in \R$, la función $y \mapsto f(x-y)g(y)$, $y \in \R$, es integrable. Por tanto, puede definirse una función $f \ast g \colon \R \to \R$ mediante
\[f \ast g(x) = \int_\R f(x-y)g(y) \, dy\]
si esta integral tiene sentido, y $f \ast g(x) = 0$ si no lo tiene. Así definida, se comprueba que $f\ast g \in L^1(\R)$. Por motivos evidentes, se dice que $f \ast g$ es la \emph{convolución de $f$ y $g$}.

Es fácil probar que la convolución es asociativa, conmutativa y distributiva respecto de la suma de funciones.

\begin{proposition}\label{pro:B.2.2}
    Si $f,g \in L^1(\R)$, entonces
    \[\widehat{f \ast g} = \sqrt{2\pi}\widehat{f}\widehat{g}.\]
\end{proposition}

\begin{proof}
    
\end{proof}

\section{Ejemplos importantes}

\begin{example}
    Sea $a > 0$ y sea $f \colon \R \to \R$ la función definida por $f(x)=\chi_{(-a,a)}(x)$. Entonces $f \in L^1(\R)$ y
    \[\widehat{f}(\xi) = \begin{cases}
        \displaystyle \sqrt{\frac{2}{\pi}}\frac{\sen(a\xi)}{\xi} & $ si $ \xi \neq 0, \\[20pt]
        \displaystyle \sqrt{\frac{2}{\pi}}a & $ si $ \xi = 0.
    \end{cases}\]
\end{example}

\begin{example}\label{eje:B.3.2}
    Sea $a > 0$ y sea $k_a \colon \R \to \R$ la función definida por $k_a(x) = e^{-ax^2}$. Entonces $k_a \in L^1(\R)$ y
    \[\widehat{k_a}(\xi) = \frac{1}{\sqrt{2a}}k_{\frac{1}{4a}}(\xi).\]
\end{example}

\section{Teorema de inversión}

Conocida la transformada de Fourier de una función de $L^1(\R)$, bajo ciertas hipótesis es posible hallar dicha función a partir de su transformada de Fourier.

\begin{theorem}[Teorema de inversión]\label{teo:B.4.1}
    Si $f \in L^1(\R)$ y $\widehat{f}\in L^1(\R)$, para casi todo $x \in \R$ se verifica
    \[f(x) = \widehat{\widehat{f}}(-x),\]
    es decir,
    \[f(x)=\frac{1}{\sqrt{2\pi}}\int_\R \widehat{f}(\xi)e^{i\xi x} \, d\xi.\]
\end{theorem}

\begin{corollary}\label{cor:B.4.2}
    Si $f,g \in L^1(\R)$ y $\widehat{f}=\widehat{g}$, entonces $f = g$ en casi todo punto.
\end{corollary}

Se recuerda que si $f,g \colon \R \to \C$ son continuas y $f = g$ en casi todo punto, entonces $f = g$ en todo punto. Por tanto, en el corolario anterior da lo mismo escribir $\widehat{f} = \widehat{g}$ que escribir \emph{$\widehat{f} = \widehat{g}$ en casi todo punto}.

\begin{corollary}
    Si $f \in L^1(\R)$ y $\widehat{f} \in L^1(\R)$, entonces existe una función $g \colon \R \to \C$ continua y con $f = g$ en casi todo punto.
\end{corollary}

\begin{example}
    Sea $f \colon \R \to \R$ la función dada por
    \[f(x)=\begin{cases}
        \cos(x) & $ si $ -\pi < x < \pi, \\
        0 & $ en otro caso$.
    \end{cases}\]
    Entonces $\widehat{f} \not\in L^1(\R)$, pues si fuese $\widehat{f} \in L^1(\R)$, el corolario anterior proporcionaría una función $g \colon \R \to \C$ continua tal que $f = g$ en casi todo punto, y esto es imposible.
\end{example}

\begin{corollary}
    Si $f \in L^1(\R)$ y $\widehat{f}\in L^1(\R)$, entonces
    \[\lim_{|x| \to \infty}f(x)=0.\]
\end{corollary}

En la práctica, comprobar que la transformada de Fourier de una función $f \in L^1(\R)$ pertenece a $L^1(\R)$ puede ser molesto y tedioso. El resultado siguiente aporta condicines más manejables que permiten asegurar que $\widehat{f}\in L^1(\R)$.

\begin{proposition}
    Sea $f \in L^1(\R)$. Si $f$ es de clase $2$ y $f',f'' \in L^1(\R)$, entonces $\widehat{f} \in L^1(\R)$.
\end{proposition}

\end{document}